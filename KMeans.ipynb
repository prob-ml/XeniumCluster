{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from importlib import reload\n",
    "\n",
    "# this ensures that I can update the class without losing my variables in my notebook\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .gz file\n",
    "file_path = 'data/hBreast/transcripts.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file into a DataFrame\n",
    "df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# drop cells without ids\n",
    "df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "# drop blanks and controls\n",
    "df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data, dataset_name: str, current_spot_size: int, third_dim: bool, n_clusters=15):\n",
    "    \n",
    "    clustering = XeniumCluster(data=data, dataset_name=dataset_name)\n",
    "    clustering.set_spot_size(current_spot_size)\n",
    "    clustering.create_spot_data(third_dim=third_dim, save_data=True)\n",
    "\n",
    "    print(f\"The size of the spot data is {clustering.xenium_spot_data.shape}\")\n",
    "\n",
    "    clustering.normalize_counts(clustering.xenium_spot_data)\n",
    "    clustering.generate_neighborhood_graph(clustering.xenium_spot_data, plot_pcas=False)\n",
    "\n",
    "    k_means_cluster = clustering.KMeans(clustering.xenium_spot_data, save_plot=True, K=n_clusters)\n",
    "    k_means_cluster_no_spatial = clustering.KMeans(clustering.xenium_spot_data, save_plot=True, K=n_clusters, include_spatial=False)\n",
    "    return clustering, k_means_cluster, k_means_cluster_no_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def record_results(original_data, cluster_dict, results_dir, model_name, filename, spot_size, third_dim, K=None, resolution=None, uses_spatial=True):\n",
    "\n",
    "    if resolution is not None:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim].get(\n",
    "            resolution, \n",
    "            cluster_dict[model_name][spot_size][third_dim]\n",
    "        ))\n",
    "    else:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim][uses_spatial].get(\n",
    "            K, \n",
    "            cluster_dict[model_name][spot_size][third_dim][uses_spatial]\n",
    "        ))\n",
    "    cluster_labels = np.unique(current_clustering)\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"] = np.array(current_clustering)\n",
    "    dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/clusters/{spot_size}\"\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    filepath = f\"{dirpath}/{filename}.csv\"\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].to_csv(filepath)\n",
    "    # Extracting row, col, and cluster values from the dataframe\n",
    "    rows = torch.tensor(original_data.xenium_spot_data.obs[\"row\"].astype(int))\n",
    "    cols = torch.tensor(original_data.xenium_spot_data.obs[\"col\"].astype(int))\n",
    "    clusters = torch.tensor(original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].astype(int))\n",
    "    cluster_labels = np.unique(clusters)\n",
    "\n",
    "    num_rows = int(max(rows) - min(rows) + 1)\n",
    "    num_cols = int(max(cols) - min(cols) + 1)\n",
    "\n",
    "    cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.int)\n",
    "\n",
    "    cluster_grid[rows, cols] = torch.tensor(clusters, dtype=torch.int)\n",
    "    \n",
    "    wss = {}\n",
    "    for label in cluster_labels:\n",
    "        current_cluster_locations = torch.stack(torch.where((cluster_grid == label)), axis=1).to(float)\n",
    "        wss[f\"Cluster {label}\"] = (spot_size ** 2) * torch.mean(torch.cdist(current_cluster_locations, current_cluster_locations)).item()\n",
    "        print(f\"POSSIBLE {len(cluster_labels)}\", label, wss[f\"Cluster {label}\"])\n",
    "\n",
    "    wss_dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/wss/{spot_size}/\"\n",
    "    if not os.path.exists(wss_dirpath):\n",
    "        os.makedirs(wss_dirpath)\n",
    "\n",
    "    wss_filepath = f\"{wss_dirpath}/{filename}_wss.json\"\n",
    "    with open(wss_filepath, \"w\") as f:\n",
    "        json.dump(wss, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {\"K-Means\": {}}\n",
    "wss = {\"K-Means\": {}}\n",
    "results_dir = \"results/hBreast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the spot data is (23444, 280)\n",
      "POSSIBLE 17 0 292007.86000111594\n",
      "POSSIBLE 17 1 154524.08504764715\n",
      "POSSIBLE 17 2 154566.7699694747\n",
      "POSSIBLE 17 3 189124.3843291574\n",
      "POSSIBLE 17 4 167277.59062403304\n",
      "POSSIBLE 17 5 194323.72182281112\n",
      "POSSIBLE 17 6 188629.07017426554\n",
      "POSSIBLE 17 7 173841.51144554777\n",
      "POSSIBLE 17 8 154608.37222697344\n",
      "POSSIBLE 17 9 193846.528297478\n",
      "POSSIBLE 17 10 187776.45422306954\n",
      "POSSIBLE 17 11 186736.10122293705\n",
      "POSSIBLE 17 12 166597.07606130574\n",
      "POSSIBLE 17 13 176141.93868535035\n",
      "POSSIBLE 17 14 135551.91034537138\n",
      "POSSIBLE 17 15 199096.83931001992\n",
      "POSSIBLE 17 16 132213.95791114107\n",
      "POSSIBLE 17 0 291441.70730021724\n",
      "POSSIBLE 17 1 175790.24633367689\n",
      "POSSIBLE 17 2 160632.5327599815\n",
      "POSSIBLE 17 3 193981.1462787553\n",
      "POSSIBLE 17 4 136934.95386809186\n",
      "POSSIBLE 17 5 170471.62180310563\n",
      "POSSIBLE 17 6 211390.55474384848\n",
      "POSSIBLE 17 7 192980.36404662105\n",
      "POSSIBLE 17 8 167709.88065736849\n",
      "POSSIBLE 17 9 192084.35760352135\n",
      "POSSIBLE 17 10 193373.04916139232\n",
      "POSSIBLE 17 11 160565.04071196032\n",
      "POSSIBLE 17 12 185164.34730668354\n",
      "POSSIBLE 17 13 158969.58759757917\n",
      "POSSIBLE 17 14 201761.340458576\n",
      "POSSIBLE 17 15 155129.50633241277\n",
      "POSSIBLE 17 16 167607.65283190858\n",
      "Cluster with spot size (50, False, 17) completed.\n",
      "The size of the spot data is (10734, 280)\n",
      "POSSIBLE 17 0 410833.6588659955\n",
      "POSSIBLE 17 1 290962.48051700625\n",
      "POSSIBLE 17 2 257312.27276008233\n",
      "POSSIBLE 17 3 250222.68172724626\n",
      "POSSIBLE 17 4 273718.02609528095\n",
      "POSSIBLE 17 5 199822.3456893357\n",
      "POSSIBLE 17 6 228509.2869187346\n",
      "POSSIBLE 17 7 230766.5835905375\n",
      "POSSIBLE 17 8 281314.1943280767\n",
      "POSSIBLE 17 9 256797.07475164623\n",
      "POSSIBLE 17 10 290354.1600029985\n",
      "POSSIBLE 17 11 284125.29696073325\n",
      "POSSIBLE 17 12 297474.8078892911\n",
      "POSSIBLE 17 13 216991.90386466836\n",
      "POSSIBLE 17 14 242337.03274496537\n",
      "POSSIBLE 17 15 285023.4103967542\n",
      "POSSIBLE 17 16 277282.38963377976\n",
      "POSSIBLE 17 0 425668.21406883426\n",
      "POSSIBLE 17 1 286532.62555793335\n",
      "POSSIBLE 17 2 281716.3107068228\n",
      "POSSIBLE 17 3 227878.31160497494\n",
      "POSSIBLE 17 4 282332.47933472024\n",
      "POSSIBLE 17 5 234290.7489078307\n",
      "POSSIBLE 17 6 224139.26123183104\n",
      "POSSIBLE 17 7 187577.9351621711\n",
      "POSSIBLE 17 8 208934.9706411256\n",
      "POSSIBLE 17 9 233850.33039907736\n",
      "POSSIBLE 17 10 302043.4632879209\n",
      "POSSIBLE 17 11 252852.0705574022\n",
      "POSSIBLE 17 12 249231.3835992677\n",
      "POSSIBLE 17 13 294498.3117880593\n",
      "POSSIBLE 17 14 283822.93500076554\n",
      "POSSIBLE 17 15 299614.701174733\n",
      "POSSIBLE 17 16 288699.4074826764\n",
      "Cluster with spot size (75, False, 17) completed.\n",
      "The size of the spot data is (6138, 280)\n",
      "POSSIBLE 17 0 580199.9962534637\n",
      "POSSIBLE 17 1 331327.5029297176\n",
      "POSSIBLE 17 2 299618.60052571405\n",
      "POSSIBLE 17 3 407583.7879955718\n",
      "POSSIBLE 17 4 330934.7160004515\n",
      "POSSIBLE 17 5 401831.71258571645\n",
      "POSSIBLE 17 6 432622.96802391484\n",
      "POSSIBLE 17 7 375854.48016361555\n",
      "POSSIBLE 17 8 394259.7969254769\n",
      "POSSIBLE 17 9 216407.68326945262\n",
      "POSSIBLE 17 10 268760.4325341989\n",
      "POSSIBLE 17 11 314478.56640088983\n",
      "POSSIBLE 17 12 339951.7279693342\n",
      "POSSIBLE 17 13 362532.37324881594\n",
      "POSSIBLE 17 14 278951.49285671534\n",
      "POSSIBLE 17 15 293601.37250582495\n",
      "POSSIBLE 17 16 362201.1694409177\n",
      "POSSIBLE 17 0 590915.77046607\n",
      "POSSIBLE 17 1 306728.54643649986\n",
      "POSSIBLE 17 2 377973.46318374627\n",
      "POSSIBLE 17 3 325027.83121266984\n",
      "POSSIBLE 17 4 421950.9644543887\n",
      "POSSIBLE 17 5 286665.4453241828\n",
      "POSSIBLE 17 6 356895.9566144741\n",
      "POSSIBLE 17 7 270745.9617048538\n",
      "POSSIBLE 17 8 327033.96129443304\n",
      "POSSIBLE 17 9 251359.80815865158\n",
      "POSSIBLE 17 10 385298.70177904377\n",
      "POSSIBLE 17 11 339449.3904592979\n",
      "POSSIBLE 17 12 399425.95570095186\n",
      "POSSIBLE 17 13 313306.26782969566\n",
      "POSSIBLE 17 14 288572.504539855\n",
      "POSSIBLE 17 15 332526.2294598979\n",
      "POSSIBLE 17 16 374039.8444351946\n",
      "Cluster with spot size (100, False, 17) completed.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "for spot_size in [50, 75, 100]:\n",
    "    for third_dim in [False]:\n",
    "        for K in [17]:\n",
    "            cluster_results_filename = f\"clusters_K={K}\"\n",
    "            original_data, k_means_cluster, k_means_cluster_no_spatial = run_experiment(df_transcripts, \"hBreast\", spot_size, third_dim, n_clusters=K)\n",
    "            # K-Means Spatial\n",
    "            if \"K-Means\" not in cluster_dict:\n",
    "                cluster_dict[\"K-Means\"] = {}\n",
    "            if spot_size not in cluster_dict[\"K-Means\"]:\n",
    "                cluster_dict[\"K-Means\"][spot_size] = {}\n",
    "            cluster_dict[\"K-Means\"][spot_size][third_dim] = {True: {K: k_means_cluster.tolist()}}\n",
    "            record_results(original_data, cluster_dict, results_dir, \"K-Means\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=True)\n",
    "\n",
    "            # K-Means No Spatial\n",
    "            if \"K-Means_No_Spatial\" not in cluster_dict:\n",
    "                cluster_dict[\"K-Means_No_Spatial\"] = {}\n",
    "            if spot_size not in cluster_dict[\"K-Means_No_Spatial\"]:\n",
    "                cluster_dict[\"K-Means_No_Spatial\"][spot_size] = {}\n",
    "            cluster_dict[\"K-Means_No_Spatial\"][spot_size][third_dim] = {False: {K: k_means_cluster_no_spatial.tolist()}}\n",
    "            record_results(original_data, cluster_dict, results_dir, \"K-Means_No_Spatial\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=False)\n",
    "\n",
    "            print(f\"Cluster with spot size {(spot_size, third_dim, K)} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "Method: K-Means Spot Size 50 Num Clusters: 17 Total WSS 0.0030468641716976993\n",
      "75\n",
      "75\n",
      "Method: K-Means Spot Size 75 Num Clusters: 17 Total WSS 0.004573847606737133\n",
      "100\n",
      "100\n",
      "Method: K-Means Spot Size 100 Num Clusters: 17 Total WSS 0.00599111837962979\n",
      "50\n",
      "50\n",
      "Method: K-Means_No_Spatial Spot Size 50 Num Clusters: 17 Total WSS 0.003115987889795701\n",
      "75\n",
      "75\n",
      "Method: K-Means_No_Spatial Spot Size 75 Num Clusters: 17 Total WSS 0.004563683460506147\n",
      "100\n",
      "100\n",
      "Method: K-Means_No_Spatial Spot Size 100 Num Clusters: 17 Total WSS 0.005947916603053906\n"
     ]
    }
   ],
   "source": [
    "spot_sizes = [50,75,100]\n",
    "methods = [\"K-Means\", \"K-Means_No_Spatial\"]\n",
    "in_billions = 1_000_000_000\n",
    "for method in methods:\n",
    "    for spot_size in spot_sizes:\n",
    "        print(spot_size)\n",
    "        for K in [17]:\n",
    "            filename = f\"results/hBreast/{method}/{K}/wss/{spot_size}/{cluster_results_filename}_wss.json\"\n",
    "            if os.path.exists(filename):\n",
    "                print(spot_size)\n",
    "                with open(filename, \"r\") as wss_dict:\n",
    "                    current_wss = json.load(wss_dict)\n",
    "                print(\"Method:\", method, \"Spot Size\", spot_size, \"Num Clusters:\", len(current_wss), \"Total WSS\", sum(current_wss.values()) / in_billions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
