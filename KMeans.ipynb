{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from importlib import reload\n",
    "\n",
    "# this ensures that I can update the class without losing my variables in my notebook\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .gz file\n",
    "file_path = 'data/hBreast/transcripts.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file into a DataFrame\n",
    "df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# drop cells without ids\n",
    "df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "# drop blanks and controls\n",
    "df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data, dataset_name: str, current_spot_size: int, third_dim: bool, n_clusters=15):\n",
    "    \n",
    "    clustering = XeniumCluster(data=data, dataset_name=dataset_name)\n",
    "    clustering.set_spot_size(current_spot_size)\n",
    "    clustering.create_spot_data(third_dim=third_dim, save_data=True)\n",
    "\n",
    "    print(f\"The size of the spot data is {clustering.xenium_spot_data.shape}\")\n",
    "\n",
    "    clustering.normalize_counts(clustering.xenium_spot_data)\n",
    "    clustering.generate_neighborhood_graph(clustering.xenium_spot_data, plot_pcas=False)\n",
    "\n",
    "    k_means_cluster = clustering.KMeans(clustering.xenium_spot_data, save_plot=True, K=n_clusters)\n",
    "    k_means_cluster_no_spatial = clustering.KMeans(clustering.xenium_spot_data, save_plot=True, K=n_clusters, include_spatial=False)\n",
    "    return clustering, k_means_cluster, k_means_cluster_no_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def record_results(original_data, cluster_dict, results_dir, model_name, filename, spot_size, third_dim, K=None, resolution=None, uses_spatial=True):\n",
    "\n",
    "    wss = {}\n",
    "    if resolution is not None:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim].get(\n",
    "            resolution, \n",
    "            cluster_dict[model_name][spot_size][third_dim]\n",
    "        ))\n",
    "    else:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim][uses_spatial].get(\n",
    "            K, \n",
    "            cluster_dict[model_name][spot_size][third_dim][uses_spatial]\n",
    "        ))\n",
    "    cluster_labels = np.unique(current_clustering)\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"] = np.array(current_clustering)\n",
    "    dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/clusters/{spot_size}\"\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    filepath = f\"{dirpath}/{filename}.csv\"\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].to_csv(filepath)\n",
    "    # Extracting row, col, and cluster values from the dataframe\n",
    "    rows = torch.tensor(original_data.xenium_spot_data.obs[\"row\"].astype(int))\n",
    "    cols = torch.tensor(original_data.xenium_spot_data.obs[\"col\"].astype(int))\n",
    "    clusters = torch.tensor(original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].astype(int))\n",
    "    cluster_labels = np.unique(clusters)\n",
    "\n",
    "    num_rows = int(max(rows) - min(rows) + 1)\n",
    "    num_cols = int(max(cols) - min(cols) + 1)\n",
    "\n",
    "    cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.int)\n",
    "\n",
    "    cluster_grid[rows, cols] = torch.tensor(clusters, dtype=torch.int)\n",
    "\n",
    "    for label in cluster_labels:\n",
    "        current_cluster_locations = torch.stack(torch.where((cluster_grid == label)), axis=1).to(float)\n",
    "        wss[f\"Cluster {label}\"] = (spot_size ** 2) * torch.mean(torch.cdist(current_cluster_locations, current_cluster_locations)).item()\n",
    "        print(f\"POSSIBLE {len(cluster_labels)}\", label, wss[f\"Cluster {label}\"])\n",
    "\n",
    "    wss_dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/wss/{spot_size}/\"\n",
    "    if not os.path.exists(wss_dirpath):\n",
    "        os.makedirs(wss_dirpath)\n",
    "\n",
    "    wss_filepath = f\"{wss_dirpath}/{filename}_wss.json\"\n",
    "    with open(wss_filepath, \"w\") as f:\n",
    "        json.dump(wss, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {\"K-Means\": {}}\n",
    "wss = {\"K-Means\": {}}\n",
    "results_dir = \"results/hBreast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resolutions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m third_dim \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mFalse\u001b[39;00m]:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m K \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m17\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m         original_data, k_means_cluster, k_means_cluster_no_spatial \u001b[38;5;241m=\u001b[39m run_experiment(df_transcripts, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhBreast\u001b[39m\u001b[38;5;124m\"\u001b[39m, spot_size, third_dim, \u001b[43mresolutions\u001b[49m, n_clusters\u001b[38;5;241m=\u001b[39mK)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# K-Means Spatial\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK-Means\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cluster_dict:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resolutions' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "for spot_size in [50, 75, 100]:\n",
    "    for third_dim in [False]:\n",
    "        for K in [17]:\n",
    "            cluster_results_filename = f\"clusters_K={K}\"\n",
    "            original_data, k_means_cluster, k_means_cluster_no_spatial = run_experiment(df_transcripts, \"hBreast\", spot_size, third_dim, n_clusters=K)\n",
    "            # K-Means Spatial\n",
    "            if \"K-Means\" not in cluster_dict:\n",
    "                cluster_dict[\"K-Means\"] = {}\n",
    "            if spot_size not in cluster_dict[\"K-Means\"]:\n",
    "                cluster_dict[\"K-Means\"][spot_size] = {}\n",
    "            cluster_dict[\"K-Means\"][spot_size][third_dim] = {True: {K: k_means_cluster.tolist()}}\n",
    "            record_results(original_data, cluster_dict, results_dir, \"K-Means\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=True)\n",
    "\n",
    "            # K-Means No Spatial\n",
    "            if \"K-Means_No_Spatial\" not in cluster_dict:\n",
    "                cluster_dict[\"K-Means_No_Spatial\"] = {}\n",
    "            if spot_size not in cluster_dict[\"K-Means_No_Spatial\"]:\n",
    "                cluster_dict[\"K-Means_No_Spatial\"][spot_size] = {}\n",
    "            cluster_dict[\"K-Means_No_Spatial\"][spot_size][third_dim] = {False: {K: k_means_cluster_no_spatial.tolist()}}\n",
    "            record_results(original_data, cluster_dict, results_dir, \"K-Means_No_Spatial\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=False)\n",
    "\n",
    "            print(f\"Cluster with spot size {(spot_size, third_dim, K)} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "Method: K-Means Spot Size 50 Num Clusters: 17 Total WSS 0.002963588978403141\n",
      "75\n",
      "75\n",
      "Method: K-Means Spot Size 75 Num Clusters: 17 Total WSS 0.004464501089126243\n",
      "100\n",
      "100\n",
      "Method: K-Means Spot Size 100 Num Clusters: 17 Total WSS 0.0057901266841228\n",
      "50\n",
      "50\n",
      "Method: K-Means_No_Spatial Spot Size 50 Num Clusters: 17 Total WSS 0.003068175933337537\n",
      "75\n",
      "75\n",
      "Method: K-Means_No_Spatial Spot Size 75 Num Clusters: 17 Total WSS 0.004491039033548089\n",
      "100\n",
      "100\n",
      "Method: K-Means_No_Spatial Spot Size 100 Num Clusters: 17 Total WSS 0.005938031301073356\n"
     ]
    }
   ],
   "source": [
    "spot_sizes = [50,75,100]\n",
    "methods = [\"K-Means\", \"K-Means_No_Spatial\"]\n",
    "in_billions = 1_000_000_000\n",
    "for method in methods:\n",
    "    for spot_size in spot_sizes:\n",
    "        print(spot_size)\n",
    "        for K in [17]:\n",
    "            filename = f\"results/hBreast/{method}/{K}/wss/{spot_size}/{cluster_results_filename}_wss.json\"\n",
    "            if os.path.exists(filename):\n",
    "                print(spot_size)\n",
    "                with open(filename, \"r\") as wss_dict:\n",
    "                    current_wss = json.load(wss_dict)\n",
    "                print(\"Method:\", method, \"Spot Size\", spot_size, \"Num Clusters:\", len(current_wss), \"Total WSS\", sum(current_wss.values()) / in_billions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
