{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from importlib import reload\n",
    "\n",
    "# this ensures that I can update the class without losing my variables in my notebook\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .gz file\n",
    "file_path = 'data/hBreast/transcripts.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file into a DataFrame\n",
    "df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# drop cells without ids\n",
    "df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "# drop blanks and controls\n",
    "df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data, dataset_name: str, current_spot_size: int, third_dim: bool, n_clusters=15):\n",
    "    \n",
    "    clustering = XeniumCluster(data=data, dataset_name=dataset_name)\n",
    "    clustering.set_spot_size(current_spot_size)\n",
    "    clustering.create_spot_data(third_dim=third_dim, save_data=True)\n",
    "\n",
    "    print(f\"The size of the spot data is {clustering.xenium_spot_data.shape}\")\n",
    "\n",
    "    clustering.normalize_counts(clustering.xenium_spot_data)\n",
    "    clustering.generate_neighborhood_graph(clustering.xenium_spot_data, plot_pcas=False)\n",
    "\n",
    "    k_means_cluster = clustering.KMeans(clustering.xenium_spot_data, save_plot=True, K=n_clusters)\n",
    "    k_means_cluster_no_spatial = clustering.KMeans(clustering.xenium_spot_data, save_plot=True, K=n_clusters, include_spatial=False)\n",
    "    return clustering, k_means_cluster, k_means_cluster_no_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def record_results(original_data, cluster_dict, results_dir, model_name, filename, spot_size, third_dim, K=None, resolution=None, uses_spatial=True):\n",
    "\n",
    "    if resolution is not None:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim].get(\n",
    "            resolution, \n",
    "            cluster_dict[model_name][spot_size][third_dim]\n",
    "        ))\n",
    "    else:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim][uses_spatial].get(\n",
    "            K, \n",
    "            cluster_dict[model_name][spot_size][third_dim][uses_spatial]\n",
    "        ))\n",
    "    cluster_labels = np.unique(current_clustering)\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"] = np.array(current_clustering)\n",
    "    dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/clusters/{spot_size}\"\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    filepath = f\"{dirpath}/{filename}.csv\"\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].to_csv(filepath)\n",
    "    # Extracting row, col, and cluster values from the dataframe\n",
    "    rows = torch.tensor(original_data.xenium_spot_data.obs[\"row\"].astype(int))\n",
    "    cols = torch.tensor(original_data.xenium_spot_data.obs[\"col\"].astype(int))\n",
    "    clusters = torch.tensor(original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].astype(int))\n",
    "    cluster_labels = np.unique(clusters)\n",
    "\n",
    "    num_rows = int(max(rows) - min(rows) + 1)\n",
    "    num_cols = int(max(cols) - min(cols) + 1)\n",
    "\n",
    "    cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.int)\n",
    "\n",
    "    cluster_grid[rows, cols] = torch.tensor(clusters, dtype=torch.int)\n",
    "    \n",
    "    wss = {}\n",
    "    for label in cluster_labels:\n",
    "        current_cluster_locations = torch.stack(torch.where((cluster_grid == label)), axis=1).to(float)\n",
    "        wss[f\"Cluster {label}\"] = (spot_size ** 2) * torch.mean(torch.cdist(current_cluster_locations, current_cluster_locations)).item()\n",
    "        print(f\"POSSIBLE {len(cluster_labels)}\", label, wss[f\"Cluster {label}\"])\n",
    "\n",
    "    wss_dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/wss/{spot_size}/\"\n",
    "    if not os.path.exists(wss_dirpath):\n",
    "        os.makedirs(wss_dirpath)\n",
    "\n",
    "    wss_filepath = f\"{wss_dirpath}/{filename}_wss.json\"\n",
    "    with open(wss_filepath, \"w\") as f:\n",
    "        json.dump(wss, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {\"K-Means\": {}}\n",
    "wss = {\"K-Means\": {}}\n",
    "results_dir = \"results/hBreast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the spot data is (23444, 280)\n",
      "POSSIBLE 17 0 275238.23349812505\n",
      "POSSIBLE 17 1 201571.67743681872\n",
      "POSSIBLE 17 2 177446.97401227552\n",
      "POSSIBLE 17 3 175109.72773690562\n",
      "POSSIBLE 17 4 145501.39942954326\n",
      "POSSIBLE 17 5 190081.16209611305\n",
      "POSSIBLE 17 6 159493.2966810456\n",
      "POSSIBLE 17 7 199758.80087713612\n",
      "POSSIBLE 17 8 155660.2513333816\n",
      "POSSIBLE 17 9 149010.23439164663\n",
      "POSSIBLE 17 10 173563.6352486485\n",
      "POSSIBLE 17 11 188771.15494948532\n",
      "POSSIBLE 17 12 153582.22803976134\n",
      "POSSIBLE 17 13 173178.1935664512\n",
      "POSSIBLE 17 14 193421.79625476507\n",
      "POSSIBLE 17 15 154663.74331381798\n",
      "POSSIBLE 17 16 159835.56924355874\n",
      "POSSIBLE 17 0 289532.24908019474\n",
      "POSSIBLE 17 1 160302.472990233\n",
      "POSSIBLE 17 2 192106.96398726196\n",
      "POSSIBLE 17 3 188943.643357102\n",
      "POSSIBLE 17 4 158152.5542001083\n",
      "POSSIBLE 17 5 154663.74331381798\n",
      "POSSIBLE 17 6 204753.1961729318\n",
      "POSSIBLE 17 7 157074.55945909355\n",
      "POSSIBLE 17 8 172310.08867643692\n",
      "POSSIBLE 17 9 199721.28864979156\n",
      "POSSIBLE 17 10 148578.78680035297\n",
      "POSSIBLE 17 11 172414.99214342426\n",
      "POSSIBLE 17 12 194356.4955985811\n",
      "POSSIBLE 17 13 155341.4854746645\n",
      "POSSIBLE 17 14 171103.8541036626\n",
      "POSSIBLE 17 15 194443.71051093264\n",
      "POSSIBLE 17 16 127850.48996535725\n",
      "Cluster with spot size (50, False, 17) completed.\n",
      "The size of the spot data is (10734, 280)\n",
      "POSSIBLE 17 0 445101.2855984092\n",
      "POSSIBLE 17 1 221958.68344077302\n",
      "POSSIBLE 17 2 227392.6843177749\n",
      "POSSIBLE 17 3 199653.4751357332\n",
      "POSSIBLE 17 4 234317.74120586744\n",
      "POSSIBLE 17 5 291757.89338520635\n",
      "POSSIBLE 17 6 227521.71455339194\n",
      "POSSIBLE 17 7 294416.250168834\n",
      "POSSIBLE 17 8 194712.74522144784\n",
      "POSSIBLE 17 9 283825.6345832516\n",
      "POSSIBLE 17 10 293258.0993509971\n",
      "POSSIBLE 17 11 251363.94865485837\n",
      "POSSIBLE 17 12 252181.08045799236\n",
      "POSSIBLE 17 13 275478.9637162097\n",
      "POSSIBLE 17 14 232202.08303853142\n",
      "POSSIBLE 17 15 254472.05959645877\n",
      "POSSIBLE 17 16 296540.8877078824\n",
      "POSSIBLE 17 0 433874.87212601\n",
      "POSSIBLE 17 1 246398.0360384443\n",
      "POSSIBLE 17 2 267956.37432718056\n",
      "POSSIBLE 17 3 192721.47478609093\n",
      "POSSIBLE 17 4 295135.2940557342\n",
      "POSSIBLE 17 5 233991.1577646684\n",
      "POSSIBLE 17 6 289577.4831531945\n",
      "POSSIBLE 17 7 199653.4751357332\n",
      "POSSIBLE 17 8 251705.42971362727\n",
      "POSSIBLE 17 9 285251.19363414537\n",
      "POSSIBLE 17 10 262442.3961809741\n",
      "POSSIBLE 17 11 228715.3087727825\n",
      "POSSIBLE 17 12 228275.03321771737\n",
      "POSSIBLE 17 13 299787.26398794935\n",
      "POSSIBLE 17 14 281316.8882968289\n",
      "POSSIBLE 17 15 289378.8795381698\n",
      "POSSIBLE 17 16 260505.05348480135\n",
      "Cluster with spot size (75, False, 17) completed.\n",
      "The size of the spot data is (6138, 280)\n",
      "POSSIBLE 17 0 589537.7015634773\n",
      "POSSIBLE 17 1 107875.94550469452\n",
      "POSSIBLE 17 2 404854.37723459385\n",
      "POSSIBLE 17 3 350043.4361617547\n",
      "POSSIBLE 17 4 253661.67745530148\n",
      "POSSIBLE 17 5 393827.12158644677\n",
      "POSSIBLE 17 6 428472.0543870273\n",
      "POSSIBLE 17 7 257576.22516750137\n",
      "POSSIBLE 17 8 388563.7582351448\n",
      "POSSIBLE 17 9 262630.7859987551\n",
      "POSSIBLE 17 10 374242.7442851311\n",
      "POSSIBLE 17 11 331537.19783810957\n",
      "POSSIBLE 17 12 288578.4311942363\n",
      "POSSIBLE 17 13 304983.6356982411\n",
      "POSSIBLE 17 14 312977.8799128691\n",
      "POSSIBLE 17 15 349038.14005141775\n",
      "POSSIBLE 17 16 225037.90346545575\n",
      "POSSIBLE 17 0 595477.9502731827\n",
      "POSSIBLE 17 1 302678.1860613332\n",
      "POSSIBLE 17 2 297946.15432031057\n",
      "POSSIBLE 17 3 313124.32337164757\n",
      "POSSIBLE 17 4 392688.13498936535\n",
      "POSSIBLE 17 5 429328.0807733898\n",
      "POSSIBLE 17 6 385111.3959836181\n",
      "POSSIBLE 17 7 327001.1559604356\n",
      "POSSIBLE 17 8 340744.9687800004\n",
      "POSSIBLE 17 9 326635.82430196233\n",
      "POSSIBLE 17 10 376111.12662840425\n",
      "POSSIBLE 17 11 250582.6841809424\n",
      "POSSIBLE 17 12 308945.39026810037\n",
      "POSSIBLE 17 13 367321.7471522712\n",
      "POSSIBLE 17 14 351395.614646687\n",
      "POSSIBLE 17 15 334809.61924651254\n",
      "POSSIBLE 17 16 413451.7749697022\n",
      "Cluster with spot size (100, False, 17) completed.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "for spot_size in [50, 75, 100]:\n",
    "    for third_dim in [False]:\n",
    "        for K in [17]:\n",
    "            cluster_results_filename = f\"clusters_K={K}\"\n",
    "            original_data, k_means_cluster, k_means_cluster_no_spatial = run_experiment(df_transcripts, \"hBreast\", spot_size, third_dim, n_clusters=K)\n",
    "            # K-Means Spatial\n",
    "            if \"K-Means\" not in cluster_dict:\n",
    "                cluster_dict[\"K-Means\"] = {}\n",
    "            if spot_size not in cluster_dict[\"K-Means\"]:\n",
    "                cluster_dict[\"K-Means\"][spot_size] = {}\n",
    "            cluster_dict[\"K-Means\"][spot_size][third_dim] = {True: {K: k_means_cluster.tolist()}}\n",
    "            record_results(original_data, cluster_dict, results_dir, \"K-Means\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=True)\n",
    "\n",
    "            # K-Means No Spatial\n",
    "            if \"K-Means_No_Spatial\" not in cluster_dict:\n",
    "                cluster_dict[\"K-Means_No_Spatial\"] = {}\n",
    "            if spot_size not in cluster_dict[\"K-Means_No_Spatial\"]:\n",
    "                cluster_dict[\"K-Means_No_Spatial\"][spot_size] = {}\n",
    "            cluster_dict[\"K-Means_No_Spatial\"][spot_size][third_dim] = {False: {K: k_means_cluster_no_spatial.tolist()}}\n",
    "            record_results(original_data, cluster_dict, results_dir, \"K-Means_No_Spatial\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=False)\n",
    "\n",
    "            print(f\"Cluster with spot size {(spot_size, third_dim, K)} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "Method: K-Means Spot Size 50 Num Clusters: 17 Total WSS 0.0030258880781094794\n",
      "75\n",
      "75\n",
      "Method: K-Means Spot Size 75 Num Clusters: 17 Total WSS 0.0044761552301336195\n",
      "100\n",
      "100\n",
      "Method: K-Means Spot Size 100 Num Clusters: 17 Total WSS 0.0056234390157401575\n",
      "50\n",
      "50\n",
      "Method: K-Means_No_Spatial Spot Size 50 Num Clusters: 17 Total WSS 0.0030416505744839473\n",
      "75\n",
      "75\n",
      "Method: K-Means_No_Spatial Spot Size 75 Num Clusters: 17 Total WSS 0.004546685614214051\n",
      "100\n",
      "100\n",
      "Method: K-Means_No_Spatial Spot Size 100 Num Clusters: 17 Total WSS 0.006113354131907866\n"
     ]
    }
   ],
   "source": [
    "spot_sizes = [50,75,100]\n",
    "methods = [\"K-Means\", \"K-Means_No_Spatial\"]\n",
    "in_billions = 1_000_000_000\n",
    "for method in methods:\n",
    "    for spot_size in spot_sizes:\n",
    "        print(spot_size)\n",
    "        for K in [17]:\n",
    "            filename = f\"results/hBreast/{method}/{K}/wss/{spot_size}/{cluster_results_filename}_wss.json\"\n",
    "            if os.path.exists(filename):\n",
    "                print(spot_size)\n",
    "                with open(filename, \"r\") as wss_dict:\n",
    "                    current_wss = json.load(wss_dict)\n",
    "                print(\"Method:\", method, \"Spot Size\", spot_size, \"Num Clusters:\", len(current_wss), \"Total WSS\", sum(current_wss.values()) / in_billions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
