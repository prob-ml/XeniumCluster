{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import pyro\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceMeanField_ELBO\n",
    "from pyro.optim import PyroOptim\n",
    "from torch.optim import Adam\n",
    "import pyro.distributions as dist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.cm import get_cmap\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial import KDTree\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import subprocess\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from importlib import reload\n",
    "\n",
    "# this ensures that I can update the class without losing my variables in my notebook\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "from utils.metrics import *\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_Xenium_data(\n",
    "        dataset=\"hBreast\", \n",
    "        spots=True, \n",
    "        spot_size=100, \n",
    "        third_dim=False, \n",
    "        log_normalize=True,\n",
    "        likelihood_mode=\"PCA\",\n",
    "        num_pcs=5,\n",
    "        hvg_var_prop=0.5,\n",
    "        min_expressions_per_spot=10\n",
    "    ):\n",
    "\n",
    "    data_filepath = f\"data/spot_data/{dataset}/hBreast_SPOTSIZE={spot_size}um_z={third_dim}.h5ad\"\n",
    "    \n",
    "    if spots:\n",
    "\n",
    "        if os.path.exists(data_filepath):\n",
    "\n",
    "            clustering = XeniumCluster(data=None, dataset_name=\"hBreast\")\n",
    "            clustering.set_spot_size(spot_size)\n",
    "            print(\"Loading data.\")\n",
    "            clustering.xenium_spot_data = ad.read_h5ad(data_filepath)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Path to your .gz file\n",
    "            file_path = f'data/{dataset}/transcripts.csv.gz'\n",
    "\n",
    "            # Read the gzipped CSV file into a DataFrame\n",
    "            df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "            df_transcripts[\"error_prob\"] = 10 ** (-df_transcripts[\"qv\"]/10)\n",
    "            df_transcripts.head(), df_transcripts.shape\n",
    "\n",
    "            # drop cells without ids\n",
    "            df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "            # drop blanks and controls\n",
    "            df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]\n",
    "\n",
    "            clustering = XeniumCluster(data=df_transcripts, dataset_name=\"hBreast\")\n",
    "            clustering.set_spot_size(spot_size)\n",
    "\n",
    "            if not os.path.exists(data_filepath):\n",
    "                print(\"Generating and saving data\")\n",
    "                clustering.create_spot_data(third_dim=third_dim, save_data=True)\n",
    "                clustering.xenium_spot_data.write_h5ad(data_filepath)\n",
    "\n",
    "        print(\"Number of spots: \", clustering.xenium_spot_data.shape[0])\n",
    "        clustering.xenium_spot_data = clustering.xenium_spot_data[clustering.xenium_spot_data.X.sum(axis=1) > min_expressions_per_spot]\n",
    "        print(\"Number of spots after filtering: \", clustering.xenium_spot_data.shape[0])\n",
    "\n",
    "        if log_normalize:\n",
    "            clustering.normalize_counts(clustering.xenium_spot_data)\n",
    "\n",
    "        if likelihood_mode == \"PCA\":\n",
    "            sc.tl.pca(clustering.xenium_spot_data, svd_solver='arpack', n_comps=num_pcs)\n",
    "            data = clustering.xenium_spot_data.obsm[\"X_pca\"]\n",
    "        elif likelihood_mode == \"HVG\":\n",
    "            min_dispersion = torch.distributions.normal.Normal(0.0, 1.0).icdf(hvg_var_prop)\n",
    "            clustering.filter_only_high_variable_genes(clustering.xenium_spot_data, flavor=\"seurat\", min_mean=0.0125, max_mean=1000, min_disp=min_dispersion)\n",
    "            clustering.xenium_spot_data = clustering.xenium_spot_data[:,clustering.xenium_spot_data.var.highly_variable==True]\n",
    "            data = clustering.xenium_spot_data.X\n",
    "        elif likelihood_mode == \"ALL\":\n",
    "            data = clustering.xenium_spot_data.X\n",
    "\n",
    "        spatial_locations = clustering.xenium_spot_data.obs[[\"row\", \"col\"]]\n",
    "    \n",
    "    # prepare cells data\n",
    "    else:\n",
    "\n",
    "        cells = df_transcripts.groupby(['cell_id', 'feature_name']).size().reset_index(name='count')\n",
    "        cells_pivot = cells.pivot_table(index='cell_id', \n",
    "                                        columns='feature_name', \n",
    "                                        values='count', \n",
    "                                        fill_value=0)\n",
    "        \n",
    "        location_means = df_transcripts.groupby('cell_id').agg({\n",
    "            'x_location': 'mean',\n",
    "            'y_location': 'mean',\n",
    "            'z_location': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        cells_pivot = location_means.join(cells_pivot, on='cell_id')\n",
    "\n",
    "        if log_normalize:\n",
    "            # log normalization\n",
    "            cells_pivot.iloc[:, 4:] = np.log1p(cells_pivot.iloc[:, 4:])\n",
    "\n",
    "        if likelihood_mode == \"PCA\":\n",
    "            pca = PCA(n_components=num_pcs)\n",
    "            data = pca.fit_transform(cells_pivot.iloc[:, 4:])\n",
    "\n",
    "        elif likelihood_mode == \"HVG\":\n",
    "            genes = cells_pivot.iloc[:, 4:]\n",
    "            gene_variances = genes.var(axis=0)\n",
    "            gene_variances = gene_variances.sort_values(ascending=False)\n",
    "            gene_var_proportions = (gene_variances / sum(gene_variances))\n",
    "            relevant_genes = list(gene_var_proportions[(gene_var_proportions.cumsum() < hvg_var_prop)].index)\n",
    "            cells_pivot.iloc[:, 4:] = cells_pivot.iloc[:, 4:][[relevant_genes]]\n",
    "            data = cells_pivot.iloc[:, 4:]\n",
    "\n",
    "        elif likelihood_mode == \"ALL\":\n",
    "            data = cells_pivot.iloc[:, 4:]\n",
    "\n",
    "        spatial_locations = cells_pivot[[\"x_location\", \"y_location\"]]\n",
    "\n",
    "\n",
    "    return data, spatial_locations, clustering # the last one is to regain var/obs access from original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Set Enrichment Analysis (GSEA)\n",
    "\n",
    "Intro: https://www.youtube.com/watch?v=egO7Lt92gDY\n",
    "\n",
    "Results Explanation: https://www.youtube.com/watch?v=Yi4d7JIlAsM\n",
    "\n",
    "Differential Expression: https://www.youtube.com/watch?v=wIvxFEMQVwg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume n total cells\n",
    "* Calculate the total number of UMIs in each cell\n",
    "counts_per_cell: n values\n",
    "* Calculate a size factor for each cell by dividing the cell's total UMI count by the median of those n counts_per_cell\n",
    "counts_per_cell / median(counts_per_cell): n values\n",
    "* Calculate a size factor for each cluster by summing the size factors of each cell in that cluster.\n",
    "* Normalize the UMI counts for each gene in each cluster by dividing by the size factor for that cluster\n",
    "* Calculate fold change per gene by dividing the normalized total UMI counts for that gene in cluster1 by cluster2\n",
    "\n",
    "#### Introduce a pseudocount into log2(fold_change)\n",
    "'log2_fold_change': np.log2((1+gene_sums_a)/(1+size_factor_a)) -  np.log2((1+gene_sums_b)/(1+size_factor_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data.\n",
      "Number of spots:  23444\n",
      "Number of spots after filtering:  23444\n"
     ]
    }
   ],
   "source": [
    "SPOT_SIZE = 50\n",
    "LIKELIHOOD_MODE=\"PCA\"\n",
    "NUM_PCS=5\n",
    "HVG_VAR_PROP=0.9\n",
    "MARKER_GENES = [\"BANK1\", \"CEACAM6\", \"FASN\", \"FGL2\", \"IL7R\", \"KRT6B\", \"POSTN\", \"TCIM\"]\n",
    "\n",
    "gene_data, spatial_locations, original_adata = prepare_Xenium_data(\n",
    "    dataset=\"hBreast\", \n",
    "    spots=True, \n",
    "    spot_size=SPOT_SIZE, \n",
    "    third_dim=False, \n",
    "    log_normalize=False, \n",
    "    likelihood_mode=LIKELIHOOD_MODE, \n",
    "    num_pcs=NUM_PCS,\n",
    "    hvg_var_prop=HVG_VAR_PROP,\n",
    "    min_expressions_per_spot=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spot_number</th>\n",
       "      <th>x_location</th>\n",
       "      <th>y_location</th>\n",
       "      <th>z_location</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>548.426080</td>\n",
       "      <td>2218.907850</td>\n",
       "      <td>12.599341</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>550.663970</td>\n",
       "      <td>2337.095433</td>\n",
       "      <td>19.034785</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>552.062194</td>\n",
       "      <td>2358.384500</td>\n",
       "      <td>16.009149</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>551.965956</td>\n",
       "      <td>2423.005319</td>\n",
       "      <td>16.599941</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>546.802622</td>\n",
       "      <td>2483.570972</td>\n",
       "      <td>15.898581</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23439</th>\n",
       "      <td>33366</td>\n",
       "      <td>10015.713547</td>\n",
       "      <td>5868.944360</td>\n",
       "      <td>27.402354</td>\n",
       "      <td>116.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23440</th>\n",
       "      <td>33367</td>\n",
       "      <td>10018.078500</td>\n",
       "      <td>5910.929274</td>\n",
       "      <td>27.193971</td>\n",
       "      <td>117.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23441</th>\n",
       "      <td>33368</td>\n",
       "      <td>10017.667292</td>\n",
       "      <td>5977.355553</td>\n",
       "      <td>27.780879</td>\n",
       "      <td>118.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23442</th>\n",
       "      <td>33369</td>\n",
       "      <td>10015.040000</td>\n",
       "      <td>6039.822000</td>\n",
       "      <td>30.913712</td>\n",
       "      <td>119.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23443</th>\n",
       "      <td>33370</td>\n",
       "      <td>10016.142727</td>\n",
       "      <td>6060.536436</td>\n",
       "      <td>29.836884</td>\n",
       "      <td>120.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23444 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spot_number    x_location   y_location z_location    row    col  cluster\n",
       "0              43    548.426080  2218.907850  12.599341   43.0    0.0        9\n",
       "1              45    550.663970  2337.095433  19.034785   45.0    0.0        9\n",
       "2              46    552.062194  2358.384500  16.009149   46.0    0.0        9\n",
       "3              47    551.965956  2423.005319  16.599941   47.0    0.0        3\n",
       "4              48    546.802622  2483.570972  15.898581   48.0    0.0        1\n",
       "...           ...           ...          ...        ...    ...    ...      ...\n",
       "23439       33366  10015.713547  5868.944360  27.402354  116.0  190.0       11\n",
       "23440       33367  10018.078500  5910.929274  27.193971  117.0  190.0        9\n",
       "23441       33368  10017.667292  5977.355553  27.780879  118.0  190.0        9\n",
       "23442       33369  10015.040000  6039.822000  30.913712  119.0  190.0        9\n",
       "23443       33370  10016.142727  6060.536436  29.836884  120.0  190.0        9\n",
       "\n",
       "[23444 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_clustering = pd.read_csv(\"results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=K-Means/NEIGHBORSIZE=2/NUMCLUSTERS=17/SPATIALINIT=False/SAMPLEFORASSIGNMENT=False/SPATIALNORM=0.0/SPATIALPRIORMULT=1.0/SPOTSIZE=50/AGG=mean/clusters_K=17.csv\", index_col=0)\n",
    "\n",
    "original_adata.xenium_spot_data.obs[\"cluster\"] = sample_clustering.values\n",
    "original_adata.xenium_spot_data.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "\n",
    "from gseapy.plot import gseaplot\n",
    "import gseapy as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting size factors...\n",
      "Fitting dispersions...\n",
      "... done in 0.58 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 0.70 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dds = DeseqDataSet(adata=original_adata.xenium_spot_data, design_factors='cluster')\n",
    "dds.deseq2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XeniumCluster' object has no attribute 'varm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stat_res \u001b[38;5;241m=\u001b[39m \u001b[43mDeseqStats\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_adata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrast\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcluster\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/xenium-1YUjn3qu-py3.10/lib/python3.10/site-packages/pydeseq2/ds.py:152\u001b[0m, in \u001b[0;36mDeseqStats.__init__\u001b[0;34m(self, dds, contrast, alpha, cooks_filter, independent_filter, prior_LFC_var, lfc_null, alt_hypothesis, inference, quiet)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    138\u001b[0m     dds: DeseqDataSet,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     quiet: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    150\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLFC\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvarm\u001b[49m\n\u001b[1;32m    153\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide a fitted DeseqDataSet by first running the `deseq2` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdds \u001b[38;5;241m=\u001b[39m dds\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m=\u001b[39m alpha\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XeniumCluster' object has no attribute 'varm'"
     ]
    }
   ],
   "source": [
    "stat_res = DeseqStats(original_adata, contrast = ('cluster', '1', '2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_res = gp.prerank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "\n",
    "for term in list(pre_res.results):\n",
    "    out.append([term,\n",
    "               pre_res.results[term]['fdr'],\n",
    "               pre_res.results[term]['es'],\n",
    "               pre_res.results[term]['nes']])\n",
    "\n",
    "out_df = pd.DataFrame(out, columns = ['Term','fdr', 'es', 'nes']).sort_values('fdr').reset_index(drop = True)\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m term_to_graph \u001b[38;5;241m=\u001b[39m \u001b[43mout_df\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mTerm\n\u001b[1;32m      2\u001b[0m term_to_graph\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_df' is not defined"
     ]
    }
   ],
   "source": [
    "term_to_graph = out_df.iloc[0].Term\n",
    "term_to_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gseaplot(\u001b[43mpre_res\u001b[49m\u001b[38;5;241m.\u001b[39mranking, term \u001b[38;5;241m=\u001b[39m term_to_graph, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpre_res\u001b[38;5;241m.\u001b[39mresults[term_to_graph])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pre_res' is not defined"
     ]
    }
   ],
   "source": [
    "gseaplot(pre_res.ranking, term = term_to_graph, **pre_res.results[term_to_graph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
