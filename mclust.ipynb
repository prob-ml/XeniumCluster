{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from importlib import reload\n",
    "\n",
    "from mclustpy import mclustpy\n",
    "\n",
    "# this ensures that I can update the class without losing my variables in my notebook\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .gz file\n",
    "file_path = 'data/hBreast/transcripts.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file into a DataFrame\n",
    "df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# drop cells without ids\n",
    "df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "# drop blanks and controls\n",
    "df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data, dataset_name: str, current_spot_size: int, third_dim: bool, num_pcs: int, n_clusters=17, model_name: str = \"EEE\"):\n",
    "    \n",
    "    clustering = XeniumCluster(data=data, dataset_name=dataset_name)\n",
    "    clustering.set_spot_size(current_spot_size)\n",
    "    clustering.create_spot_data(third_dim=third_dim, save_data=True)\n",
    "\n",
    "    print(f\"The size of the spot data is {clustering.xenium_spot_data.shape}\")\n",
    "\n",
    "    clustering.normalize_counts(clustering.xenium_spot_data)\n",
    "    clustering.generate_neighborhood_graph(clustering.xenium_spot_data, plot_pcas=False, n_pcs = num_pcs)\n",
    "\n",
    "    clustering.pca(clustering.xenium_spot_data, num_pcs = num_pcs)\n",
    "\n",
    "    mclust_cluster = clustering.mclust(clustering.xenium_spot_data, G=n_clusters, model_name = \"EEE\")\n",
    "\n",
    "    return clustering, mclust_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_results(original_data, cluster_dict, results_dir, model_name, filename, spot_size, third_dim, num_pcs, K=None, resolution=None, uses_spatial=True):\n",
    "\n",
    "    dirpath = f\"{results_dir}/{model_name}/{num_pcs}/{(str(resolution) if resolution is not None else str(K))}/clusters/{spot_size}\"\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    current_clustering = pd.read_csv(f\"{dirpath}/{filename}.csv\", index_col=0)[\"mclust cluster\"].values\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"] = np.array(current_clustering)\n",
    "\n",
    "    # Extracting row, col, and cluster values from the dataframe\n",
    "    rows = torch.tensor(original_data.xenium_spot_data.obs[\"row\"].astype(int))\n",
    "    cols = torch.tensor(original_data.xenium_spot_data.obs[\"col\"].astype(int))\n",
    "    clusters = torch.tensor(original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].astype(int))\n",
    "    cluster_labels = np.unique(clusters)\n",
    "    num_clusters = len(cluster_labels)\n",
    "\n",
    "    num_rows = int(max(rows) - min(rows) + 1)\n",
    "    num_cols = int(max(cols) - min(cols) + 1)\n",
    "\n",
    "    cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.int)\n",
    "\n",
    "    cluster_grid[rows, cols] = torch.tensor(clusters, dtype=torch.int)\n",
    "\n",
    "    mpd = {}\n",
    "    for label in cluster_labels:\n",
    "        current_cluster_locations = torch.stack(torch.where((cluster_grid == label)), axis=1).to(float)\n",
    "        mpd[f\"Cluster {label}\"] = spot_size * torch.mean(torch.cdist(current_cluster_locations, current_cluster_locations)).item()\n",
    "        print(f\"POSSIBLE {len(cluster_labels)}\", label, mpd[f\"Cluster {label}\"])\n",
    "\n",
    "    mpd_dirpath = f\"{results_dir}/{model_name}/{num_pcs}/{(str(resolution) if resolution is not None else str(K))}/mpd/{spot_size}/\"\n",
    "    if not os.path.exists(mpd_dirpath):\n",
    "        os.makedirs(mpd_dirpath)\n",
    "\n",
    "    mpd_filepath = f\"{mpd_dirpath}/{filename}_mpd.json\"\n",
    "    with open(mpd_filepath, \"w\") as f:\n",
    "        json.dump(mpd, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {\"mclust\": {}}\n",
    "mpd = {\"mclust\": {}}\n",
    "results_dir = \"results/hBreast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_list = [3, 5, 10, 15, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the spot data is (23444, 280)\n",
      "TOTAL NUMBER OF UNIQUE CLUSTERS:  15\n",
      "POSSIBLE 15 1 167584.19356975707\n",
      "POSSIBLE 15 2 170559.17810074365\n",
      "POSSIBLE 15 3 188896.77991364626\n",
      "POSSIBLE 15 4 176810.2129674784\n",
      "POSSIBLE 15 5 166646.45761794172\n",
      "POSSIBLE 15 7 186708.15559302788\n",
      "POSSIBLE 15 8 164198.0598013789\n",
      "POSSIBLE 15 9 184210.34394690802\n",
      "POSSIBLE 15 10 178523.5728404353\n",
      "POSSIBLE 15 11 199039.67980814233\n",
      "POSSIBLE 15 12 188437.93426351078\n",
      "POSSIBLE 15 13 147805.54902816465\n",
      "POSSIBLE 15 14 201002.29108736364\n",
      "POSSIBLE 15 15 196285.18984109032\n",
      "POSSIBLE 15 16 193779.68607315017\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMost likely mclust returned a null object for setting: SPOT_SIZE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspot_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, NUM_PCS=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_pcs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, K=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "for spot_size in [50]:\n",
    "    for third_dim in [False]:\n",
    "        for K in [17]:\n",
    "            for num_pcs in PC_list:\n",
    "\n",
    "                try:\n",
    "\n",
    "                    cluster_results_filename = f\"clusters_K={K}\"\n",
    "                    original_data, mclust_cluster = run_experiment(df_transcripts, \"hBreast\", spot_size, third_dim, num_pcs, n_clusters=K)\n",
    "\n",
    "                    # mclust\n",
    "                    if \"mclust\" not in cluster_dict:\n",
    "                        cluster_dict[\"mclust\"] = {}\n",
    "                    if spot_size not in cluster_dict[\"mclust\"]:\n",
    "                        cluster_dict[\"mclust\"][spot_size] = {}\n",
    "                    if third_dim not in cluster_dict[\"mclust\"][spot_size]:\n",
    "                        cluster_dict[\"mclust\"][spot_size][third_dim] = {}\n",
    "                    cluster_dict[\"mclust\"][spot_size][third_dim][num_pcs] = {True: {K: mclust_cluster.tolist()}}\n",
    "                    record_results(original_data, cluster_dict, results_dir, \"mclust\", cluster_results_filename, spot_size, third_dim, num_pcs=num_pcs, K=K, uses_spatial=True)\n",
    "\n",
    "                except TypeError as e:\n",
    "\n",
    "                    print(f\"Most likely mclust returned a null object for setting: SPOT_SIZE={spot_size}, NUM_PCS={num_pcs}, K={K}\")\n",
    "                    print(f\"Error: {e}\")\n",
    "                \n",
    "                1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
