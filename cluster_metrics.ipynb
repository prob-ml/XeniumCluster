{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import norm\n",
    "\n",
    "from importlib import reload\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"hBreast\"\n",
    "models = [\"BayXenSmooth\", \"Leiden\", \"Louvain\", \"K-Means\", \"K-Means_No_Spatial\", \"Hierarchical\", \"Hierarchical_No_Spatial\", \"BayesSpace\"]\n",
    "resolutions = [0.75]\n",
    "spot_sizes = [100, 75, 50]\n",
    "K_values = [17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayXenSmooth Hyperparameters\n",
    "BayXenSmooth_PCs = [3, 5, 10, 25]\n",
    "BayesSpace_PCs = [3, 5, 10, 15, 25]\n",
    "neighborhood_sizes = [1,2,3,4,5]\n",
    "sample_for_assignment = False\n",
    "concentration_amp = 1.0\n",
    "spatial_norms = [0.05, 0.1]\n",
    "aggs = [\"sum\", \"mean\", \"weighted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .gz file\n",
    "file_path = f'data/{dataset_name}/transcripts.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file into a DataFrame\n",
    "df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# drop cells without ids\n",
    "df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "# drop blanks and controls\n",
    "df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Metric Implementations\n",
    "\n",
    "- Variation Index (TODO) If we want to compare competing methods clustering with our clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morans_i_cluster_similarity(clustering, locations, clusters):\n",
    "    print(\"Starting Moran's I Calculation.\")\n",
    "    moran_clusters = ad.AnnData(locations)\n",
    "    sc.pp.neighbors(moran_clusters, n_pcs=0, n_neighbors=100)\n",
    "    print(\"Neighbors calculated.\")\n",
    "\n",
    "    cluster_labels = clusters.values\n",
    "    # Calculate Moran's I for the binary presence of each cluster\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    morans_i_results = {}\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_indicator = (cluster_labels == cluster).astype(int)\n",
    "        morans_i = sc.metrics.morans_i(moran_clusters, vals=cluster_indicator)\n",
    "        morans_i_results[cluster] = morans_i\n",
    "\n",
    "    print(\"Done!\")\n",
    "    return np.mean(list(morans_i_results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gearys_c_cluster_similarity(clustering, locations, clusters):\n",
    "    print(\"Starting Gearys's C Calculation.\")\n",
    "    gearys_clusters = ad.AnnData(locations)\n",
    "    sc.pp.neighbors(gearys_clusters, n_pcs=0, n_neighbors=100)\n",
    "    print(\"Neighbors calculated.\")\n",
    "\n",
    "    cluster_labels = clusters.values\n",
    "    # Calculate Gearys C for the binary presence of each cluster\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    gearys_c_results = {}\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_indicator = (cluster_labels == cluster).astype(int)\n",
    "        gearys_c = sc.metrics.gearys_c(gearys_clusters, vals=cluster_indicator)\n",
    "        gearys_c_results[cluster] = gearys_c\n",
    "\n",
    "    print(\"Done!\")\n",
    "    return np.mean(list(gearys_c_results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, directory, metric_name, specification=None):\n",
    "    subdirectory = f\"{specification}\" if specification else \"\"\n",
    "    full_path = f\"{directory}/{subdirectory}\"\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(full_path, exist_ok=True)\n",
    "    \n",
    "    with jsonlines.open(f\"{full_path}/{metric_name}.jsonl\", mode='w') as writer:\n",
    "        try:\n",
    "            for key, value in results.items():\n",
    "                writer.write({key: value})\n",
    "        except AttributeError: # b/c it's not a dictionary so .items() fails\n",
    "            writer.write(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Silhouette Score (and other metrics of note.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for spot_size in spot_sizes:\n",
    "#     clustering = XeniumCluster(data=df_transcripts, dataset_name=dataset_name)\n",
    "#     clustering.set_spot_size(spot_size)\n",
    "#     clustering.create_spot_data(third_dim=False, save_data=True)\n",
    "#     locations = clustering.xenium_spot_data.obs[[\"row\", \"col\"]]\n",
    "#     for model in models:\n",
    "#         for K in K_values:\n",
    "#             if model in [\"Leiden\", \"Louvain\"]:\n",
    "#                 for resolution in resolutions:\n",
    "#                     clusters = pd.read_csv(f\"results/{dataset_name}/{model}/{resolution}/clusters/{spot_size}/clusters_RES={resolution}.csv\")[f\"{model} cluster\"]\n",
    "#                     save_results(silhouette_score(locations, clusters), dataset_name, model, \"silhouette_score\", spot_size, resolution=resolution)\n",
    "#                     save_results(morans_i_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"morans_i\", spot_size, resolution=resolution)\n",
    "#                     save_results(gearys_c_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"gearys_c\", spot_size, resolution=resolution)\n",
    "#             elif model == \"BayXenSmooth\":\n",
    "#                 min_expressions_per_spot = 10\n",
    "#                 clustering.xenium_spot_data = clustering.xenium_spot_data[clustering.xenium_spot_data.X.sum(axis=1) > min_expressions_per_spot]\n",
    "#                 for neighborhood_size in neighborhood_sizes:\n",
    "#                     clusters = pd.read_csv(f\"results/{dataset_name}/{model}/clusters/PCA/{BayXenSmooth_PCs}/KMEANSINIT=True/NEIGHBORSIZE={neighborhood_size}/NUMCLUSTERS={K}/SPATIALINIT=True/SAMPLEFORASSIGNMENT={sample_for_assignment}/SPATIALNORM={spatial_norm}/SPATIALPRIORMULT={concentration_amp}/SPOTSIZE={spot_size}/AGG={agg}/clusters_K={K}.csv\")[f\"{model} cluster\"]\n",
    "#                     save_results(silhouette_score(locations, clusters), dataset_name, model, \"silhouette_score\", spot_size, K=K)\n",
    "#                     save_results(morans_i_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"morans_i\", spot_size, K=K, sample_for_assignment=sample_for_assignment)\n",
    "#                     save_results(gearys_c_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"gearys_c\", spot_size, K=K, sample_for_assignment=sample_for_assignment)\n",
    "#             else:\n",
    "#                 clusters = pd.read_csv(f\"results/{dataset_name}/{model}/{K}/clusters/{spot_size}/clusters_K={K}.csv\")[f\"{model} cluster\"]\n",
    "#                 save_results(silhouette_score(locations, clusters), dataset_name, model, \"silhouette_score\", spot_size, K=K)\n",
    "#                 save_results(morans_i_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"morans_i\", spot_size, K=K)\n",
    "#                 save_results(gearys_c_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"gearys_c\", spot_size, K=K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marker Gene Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKER_GENES = [\"BANK1\", \"CEACAM6\", \"FASN\", \"FGL2\", \"IL7R\", \"KRT6B\", \"POSTN\", \"TCIM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_morans_i(clustering, moran_clusters, clusters, num_neighbors=100, kernel='umap', p=1, marker_genes=MARKER_GENES, print_output=False):\n",
    "\n",
    "    # Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "    cluster_labels = clusters.values\n",
    "    same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "\n",
    "    if kernel == 'umap':\n",
    "        sc.pp.neighbors(moran_clusters, n_neighbors=num_neighbors, use_rep='X', n_pcs=0, method=kernel)\n",
    "        moran_clusters.obsp[\"adjacency\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "    elif kernel == 'gauss':\n",
    "        sc.pp.neighbors(moran_clusters, n_neighbors=num_neighbors, use_rep='X', n_pcs=0, method=kernel)\n",
    "        moran_clusters.obsp[\"adjacency\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "    elif kernel == 'naive_distance':\n",
    "        def naive_distance(x, p=1):\n",
    "            return 1 / ((1 + x)**(1/p))\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=num_neighbors).fit(moran_clusters.X)\n",
    "        distances, indices = nbrs.kneighbors(moran_clusters.X)\n",
    "        connectivities = csr_matrix((moran_clusters.shape[0], moran_clusters.shape[0]))\n",
    "        connectivities[np.arange(len(indices))[:, None], indices] = naive_distance(distances, p)\n",
    "        moran_clusters.obsp[\"connectivities\"] = connectivities\n",
    "        moran_clusters.obsp[\"adjacency\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "    elif kernel == 'basic':\n",
    "        moran_clusters.obsp[\"adjacency\"] = csr_matrix(same_cluster)\n",
    "    else:\n",
    "        warnings.warn(f\"Kernel '{kernel}' not implemented. Using 'basic' kernel instead. We recommend 'umap'.\", UserWarning)\n",
    "        kernel = 'basic'\n",
    "        moran_clusters.obsp[\"adjacency\"] = csr_matrix(same_cluster)\n",
    "\n",
    "    # Calculate Moran's I for the genes\n",
    "    morans_i = sc.metrics.morans_i(moran_clusters.obsp[\"adjacency\"], vals=clustering.xenium_spot_data.X.T)\n",
    "    morans_i_dict = dict(zip(clustering.xenium_spot_data.var.index, morans_i))\n",
    "\n",
    "    # Print the number of non-zero adjacencies\n",
    "    if print_output:\n",
    "        num_nonzero = moran_clusters.obsp[\"adjacency\"].getnnz()\n",
    "        print(f\"Number of non-zero adjacencies: {num_nonzero}\")\n",
    "        for gene in marker_genes:\n",
    "            print(num_neighbors, gene, morans_i_dict[gene])\n",
    "\n",
    "    return morans_i_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_gearys_c(clustering, gearys_clusters, clusters, num_neighbors=100):\n",
    "\n",
    "    # Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "    cluster_labels = clusters.values\n",
    "    same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "    gearys_clusters.obsp[\"adjacency\"] = gearys_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "    print(\"Connectivities formed.\")\n",
    "\n",
    "    # Calculate Geary's C for the genes\n",
    "    gearys_c= sc.metrics.gearys_c(gearys_clusters.obsp[\"adjacency\"], vals=clustering.xenium_spot_data.X.T)\n",
    "\n",
    "    gearys_c_dict = dict(zip(clustering.xenium_spot_data.var.index, gearys_c))\n",
    "\n",
    "    return gearys_c_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"BayXenSmooth\"]\n",
    "num_neighboring_spots = [50, 100, 200, 400]\n",
    "spot_sizes = [50]\n",
    "kernels = ['umap']\n",
    "K = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot_size in spot_sizes:\n",
    "    clustering = XeniumCluster(data=df_transcripts, dataset_name=dataset_name)\n",
    "    clustering.set_spot_size(spot_size)\n",
    "    clustering.create_spot_data(third_dim=False, save_data=True)\n",
    "    locations = clustering.xenium_spot_data.obs[[\"row\", \"col\"]]\n",
    "    moran_clusters = ad.AnnData(locations)\n",
    "    gearys_clusters = ad.AnnData(locations)\n",
    "    for model in models:\n",
    "\n",
    "        moran_clusters = ad.AnnData(locations)\n",
    "        gearys_clusters = ad.AnnData(locations)\n",
    "\n",
    "        # Define the directory where the results are stored\n",
    "        results_dir = f\"results/hBreast/{model}\"\n",
    "\n",
    "        # Loop through all subdirectories in the results directory\n",
    "        for root, dirs, files in os.walk(results_dir):\n",
    "            for file in files:\n",
    "                # Check if the file is named morans_i_by_gene.json\n",
    "                if file == f\"clusters_K={K}.csv\" and str(spot_size) in root:\n",
    "\n",
    "                    for neighboring_spots in num_neighboring_spots:\n",
    "                        for kernel in kernels:\n",
    "\n",
    "                            clusters = pd.read_csv(os.path.join(root, file))[f\"{model} cluster\"]\n",
    "                            save_results(gene_morans_i(clustering, moran_clusters, clusters, num_neighbors=neighboring_spots, kernel=kernel, print_output=True), root, \"morans_i_by_gene\", specification=f\"{kernel}/{neighboring_spots}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayXenSmooth Best Moran's I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where the results are stored\n",
    "results_dir = \"results/hBreast/BayXenSmooth\"\n",
    "\n",
    "# Loop through all subdirectories in the results directory\n",
    "morans_i_dict = {}\n",
    "for gene_name in MARKER_GENES:\n",
    "    current_max_expression = 0\n",
    "    current_best_wss = float('inf')\n",
    "    for root, dirs, files in os.walk(results_dir):\n",
    "        for file in files:\n",
    "            # Check if the file is named morans_i_by_gene.json\n",
    "            if file == \"morans_i_by_gene.jsonl\":\n",
    "                # Construct the full path to the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Open and read the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    # Load the JSON data\n",
    "                    data = [line for line in jsonlines.Reader(f)]\n",
    "                    # Print the data to verify it's been loaded\n",
    "                    morans_i = [x for x in data if gene_name in x]\n",
    "                    if morans_i[0][gene_name] > current_max_expression and \"SPOTSIZE=50\" in file_path:# and \"K-Means\" in file_path:\n",
    "                        current_max_filepath = file_path\n",
    "                        current_max_expression = morans_i[0][gene_name]\n",
    "                        wss_root = root\n",
    "                        pattern = r\"(?:umap|naive_distance|gauss|basic)/\\d+\"\n",
    "                        wss_root = re.sub(pattern, \"\", wss_root)\n",
    "                        wss_dir = wss_root.replace(\"clusters\", \"wss\")\n",
    "                        wss_file = next((f for f in os.listdir(wss_dir) if f.endswith(\".json\")), None)\n",
    "                        if wss_file:\n",
    "                            with open(os.path.join(wss_dir, wss_file)) as f:\n",
    "                                wss_dict = json.load(f)\n",
    "                                if len(wss_dict) == K:\n",
    "                                    current_best_wss = sum(wss_dict.values()) / 1_000_000\n",
    "                                else:\n",
    "                                    current_best_wss = (sum(wss_dict.values()) / 1_000_000, f\"(but K* = {len(wss_dict)})\")\n",
    "    morans_i_dict[gene_name] = current_max_expression, current_max_filepath, current_best_wss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BANK1': (1.0781974514990489,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=K-Means/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=1.0/SIGMA_PRIOR=0.25/LOGITS_PRIOR=5.0/LEARN_GLOBAL_VARS=False/umap/50/morans_i_by_gene.jsonl',\n",
       "  2.9141664114437273),\n",
       " 'CEACAM6': (0.4061224468124115,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/3/INIT=mclust/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/LOGITS_PRIOR=5.0/LEARN_GLOBAL_VARS=False/umap/50/morans_i_by_gene.jsonl',\n",
       "  nan),\n",
       " 'FASN': (1.1366610517413984,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/3/INIT=mclust/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/LOGITS_PRIOR=5.0/LEARN_GLOBAL_VARS=False/umap/50/morans_i_by_gene.jsonl',\n",
       "  nan),\n",
       " 'FGL2': (0.5134246298180729,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/3/INIT=K-Means/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=1.0/SIGMA_PRIOR=0.25/LOGITS_PRIOR=1.0/LEARN_GLOBAL_VARS=True/umap/50/morans_i_by_gene.jsonl',\n",
       "  2.8353981202219782),\n",
       " 'IL7R': (0.9050722107108878,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=K-Means/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/LOGITS_PRIOR=1.0/LEARN_GLOBAL_VARS=True/umap/50/morans_i_by_gene.jsonl',\n",
       "  2.9257625580163715),\n",
       " 'KRT6B': (0.7008317196942077,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/10/INIT=K-Means/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/LOGITS_PRIOR=5.0/LEARN_GLOBAL_VARS=False/umap/50/morans_i_by_gene.jsonl',\n",
       "  2.8878609429057893),\n",
       " 'POSTN': (0.5468660491741246,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=Leiden/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=1.0/SIGMA_PRIOR=0.25/LOGITS_PRIOR=5.0/LEARN_GLOBAL_VARS=True/umap/50/morans_i_by_gene.jsonl',\n",
       "  2.5470954204524205),\n",
       " 'TCIM': (0.700568661955436,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/15/INIT=Leiden/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=1.0/SIGMA_PRIOR=0.25/LOGITS_PRIOR=5.0/LEARN_GLOBAL_VARS=True/umap/50/morans_i_by_gene.jsonl',\n",
       "  2.558285974338485)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morans_i_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Moran's I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/hBreast/BayesSpace/15/17/wss/mclust/50/2.50/wss.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m                     wss_root \u001b[38;5;241m=\u001b[39m root\n\u001b[1;32m     32\u001b[0m                     wss_root\u001b[38;5;241m.\u001b[39mreplace(pattern, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m                     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwss_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclusters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/wss.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     34\u001b[0m                         current_best_wss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(json\u001b[38;5;241m.\u001b[39mload(f)\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1_000_000\u001b[39m\n\u001b[1;32m     35\u001b[0m morans_i_dict[gene_name] \u001b[38;5;241m=\u001b[39m current_max_expression, current_max_filepath, current_best_wss\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/xenium-1YUjn3qu-py3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/hBreast/BayesSpace/15/17/wss/mclust/50/2.50/wss.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "MARKER_GENES = [\"BANK1\", \"CEACAM6\", \"FASN\", \"FGL2\", \"IL7R\", \"KRT6B\", \"POSTN\", \"TCIM\"]\n",
    "\n",
    "# Define the directory where the results are stored\n",
    "results_dir = \"results/hBreast\"\n",
    "\n",
    "# Loop through all subdirectories in the results directory\n",
    "morans_i_dict = {}\n",
    "for gene_name in MARKER_GENES:\n",
    "    current_max_expression = 0\n",
    "    current_best_wss = float('inf')\n",
    "    for root, dirs, files in os.walk(results_dir):\n",
    "        for file in files:\n",
    "            # Check if the file is named morans_i_by_gene.json\n",
    "            if file == \"morans_i_by_gene.jsonl\":\n",
    "                # Construct the full path to the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Open and read the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    # Load the JSON data\n",
    "                    data = [line for line in jsonlines.Reader(f)]\n",
    "                    # Print the data to verify it's been loaded\n",
    "                    morans_i = [x for x in data if gene_name in x]\n",
    "                    unused_runs = [\"Leiden/2.0\", \"Leiden/1.5\", \"Louvain/2.0\", \"Louvain/1.5\"]\n",
    "                    if morans_i[0][gene_name] > current_max_expression and \"50/\" in file_path and not any(x in file_path for x in unused_runs):\n",
    "                        current_max_filepath = file_path\n",
    "                        current_max_expression = morans_i[0][gene_name]\n",
    "                        wss_root = root\n",
    "                        with open(wss_root.replace(\"clusters\", \"wss\") + \"/wss.json\") as f:\n",
    "                            current_best_wss = sum(json.load(f).values()) / 1_000_000\n",
    "    morans_i_dict[gene_name] = current_max_expression, current_max_filepath, current_best_wss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morans_i_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Methods Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/hBreast/BayesSpace/15/17/wss/mclust/50/2.50/wss.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m                     current_max_expression \u001b[38;5;241m=\u001b[39m morans_i[\u001b[38;5;241m0\u001b[39m][gene_name]\n\u001b[1;32m     31\u001b[0m                     wss_root \u001b[38;5;241m=\u001b[39m root\n\u001b[0;32m---> 32\u001b[0m                     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwss_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclusters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/wss.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     33\u001b[0m                         current_best_wss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(json\u001b[38;5;241m.\u001b[39mload(f)\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1_000_000\u001b[39m\n\u001b[1;32m     34\u001b[0m morans_i_dict[gene_name] \u001b[38;5;241m=\u001b[39m current_max_expression, current_max_filepath, current_best_wss\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/xenium-1YUjn3qu-py3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/hBreast/BayesSpace/15/17/wss/mclust/50/2.50/wss.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the directory where the results are stored\n",
    "# results_dirs = [\"results/hBreast/BayXenSmooth\", \"results/hBreast/BayesSpace\"]\n",
    "results_dirs = [\"results/hBreast/BayesSpace\"]\n",
    "\n",
    "# Loop through all subdirectories in the results directory\n",
    "morans_i_dict = {}\n",
    "for gene_name in MARKER_GENES:\n",
    "    current_max_expression = 0\n",
    "    current_best_wss = float('inf')\n",
    "    for dir in results_dirs:\n",
    "        for root, dirs, files in os.walk(dir):\n",
    "            for file in files:\n",
    "                # Check if the file is named morans_i_by_gene.json\n",
    "                if file == \"morans_i_by_gene.jsonl\":\n",
    "                    # Construct the full path to the file\n",
    "                    file_path = os.path.join(root, file)\n",
    "\n",
    "                    # Open and read the file\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        # Load the JSON data\n",
    "                        data = [line for line in jsonlines.Reader(f)]\n",
    "                        # Print the data to verify it's been loaded\n",
    "                        morans_i = [x for x in data if gene_name in x]\n",
    "                        unused_runs = [\"Leiden/2.0\", \"Leiden/1.5\", \"Louvain/2.0\", \"Louvain/1.5\"]\n",
    "                        if morans_i[0][gene_name] > current_max_expression and \"50/\" in file_path and not any(x in file_path for x in unused_runs):\n",
    "                            current_max_filepath = file_path\n",
    "                            current_max_expression = morans_i[0][gene_name]\n",
    "                            wss_root = root\n",
    "                            with open(wss_root.replace(\"clusters\", \"wss\") + \"/wss.json\") as f:\n",
    "                                current_best_wss = sum(json.load(f).values()) / 1_000_000\n",
    "        morans_i_dict[gene_name] = current_max_expression, current_max_filepath, current_best_wss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BANK1': (1.4659762123719298,\n",
       "  'results/hBreast/BayesSpace/5/17/clusters/kmeans/50/1.00/morans_i_by_gene.jsonl',\n",
       "  inf),\n",
       " 'CEACAM6': (0.40848347275673375,\n",
       "  'results/hBreast/BayesSpace/3/17/clusters/kmeans/50/3.00/morans_i_by_gene.jsonl',\n",
       "  inf),\n",
       " 'FASN': (1.2292055023504695,\n",
       "  'results/hBreast/BayesSpace/3/17/clusters/mclust/50/2.75/morans_i_by_gene.jsonl',\n",
       "  inf),\n",
       " 'FGL2': (0.5887862352806054,\n",
       "  'results/hBreast/BayesSpace/5/17/clusters/kmeans/50/1.00/morans_i_by_gene.jsonl',\n",
       "  inf),\n",
       " 'IL7R': (1.2379221808248948,\n",
       "  'results/hBreast/BayesSpace/5/17/clusters/kmeans/50/1.00/morans_i_by_gene.jsonl',\n",
       "  inf),\n",
       " 'KRT6B': (0.8606124826901229,\n",
       "  'results/hBreast/BayesSpace/10/17/clusters/mclust/50/1.00/morans_i_by_gene.jsonl',\n",
       "  inf),\n",
       " 'POSTN': (0.5517063501552671,\n",
       "  'results/hBreast/BayesSpace/15/17/clusters/kmeans/50/1.00/morans_i_by_gene.jsonl',\n",
       "  inf),\n",
       " 'TCIM': (0.8347711098399502,\n",
       "  'results/hBreast/BayesSpace/15/17/clusters/kmeans/50/1.00/morans_i_by_gene.jsonl',\n",
       "  inf)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morans_i_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows.shape, bank1_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Get the index of the gene \n",
    "\n",
    "gene = \"BANK1\"\n",
    "\n",
    "bank1_index = clustering.xenium_spot_data.var.index.get_loc(gene)\n",
    "\n",
    "# Extract the data for \"BANK1\"\n",
    "bank1_data = torch.tensor(clustering.xenium_spot_data.X[:, bank1_index])\n",
    "\n",
    "rows = clustering.xenium_spot_data.obs[\"row\"].astype(int)\n",
    "columns = clustering.xenium_spot_data.obs[\"col\"].astype(int)\n",
    "\n",
    "num_rows = max(rows) + 1\n",
    "num_cols = max(columns) + 1\n",
    "\n",
    "marker_grid = torch.zeros(num_rows, num_cols, dtype=float)\n",
    "\n",
    "marker_grid[rows, columns] = bank1_data\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(marker_grid, origin='lower')  # Invert the y-axis by setting origin to 'upper'\n",
    "plt.title(f'Expression of {gene}')\n",
    "plt.xlabel('Row')\n",
    "plt.ylabel('Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(clustering.xenium_spot_data.var[\"BANK1\"], cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_per_side = 100\n",
    "\n",
    "print(\"Starting Moran's I Calculation.\")\n",
    "moran_clusters = ad.AnnData(locations)\n",
    "sc.pp.neighbors(moran_clusters, n_pcs=0, n_neighbors=100)\n",
    "print(\"Neighbors calculated.\")\n",
    "\n",
    "connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "# connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()\n",
    "\n",
    "# Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "cluster_labels = clusters.values\n",
    "same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "print(moran_clusters.obsp[\"connectivities\"].shape, same_cluster.shape)\n",
    "moran_clusters.obsp[\"connectivities\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "print(\"Connectivities formed.\")\n",
    "\n",
    "# Calculate Moran's I for the genes\n",
    "morans_i = sc.metrics.morans_i(moran_clusters, vals=clustering.xenium_spot_data.X.T)\n",
    "\n",
    "morans_i_dict = dict(zip(clustering.xenium_spot_data.var.index, morans_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_per_side = 100\n",
    "\n",
    "print(\"Starting Moran's I Calculation.\")\n",
    "moran_clusters = ad.AnnData(locations)\n",
    "sc.pp.neighbors(moran_clusters, n_pcs=0, n_neighbors=100)\n",
    "print(\"Neighbors calculated.\")\n",
    "\n",
    "connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "# connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()\n",
    "\n",
    "# Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "cluster_labels = clusters.values\n",
    "same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "print(moran_clusters.obsp[\"connectivities\"].shape, same_cluster.shape)\n",
    "moran_clusters.obsp[\"connectivities\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "print(\"Connectivities formed.\")\n",
    "\n",
    "# Calculate Moran's I for the genes\n",
    "morans_i = sc.metrics.morans_i(moran_clusters, vals=clustering.xenium_spot_data.X.T)\n",
    "\n",
    "morans_i_dict = dict(zip(clustering.xenium_spot_data.var.index, morans_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first 10x10 submatrix of the connectivities matrix\n",
    "connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "# connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spots_per_side = 100\n",
    "\n",
    "# Extract the first 10x10 submatrix of the connectivities matrix\n",
    "# connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check of Clusters and Moran's I Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "num_clusters = K\n",
    "\n",
    "rows = locations[\"row\"].astype(int)\n",
    "columns = locations[\"col\"].astype(int)\n",
    "\n",
    "num_rows = max(rows) + 1\n",
    "num_cols = max(columns) + 1\n",
    "\n",
    "cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.long)\n",
    "\n",
    "cluster_grid[rows, columns] = torch.tensor(clusters) + 1\n",
    "\n",
    "colors = plt.cm.get_cmap('viridis', num_clusters + 1)\n",
    "\n",
    "colormap_colors = np.vstack(([[1, 1, 1, 1]], colors(np.linspace(0, 1, num_clusters))))\n",
    "colormap = ListedColormap(colormap_colors)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cluster_grid, cmap=colormap, interpolation='nearest', origin='lower')\n",
    "plt.colorbar(ticks=range(num_clusters + 1), label='Cluster Values')\n",
    "plt.title('Prior Cluster Assignment with BayXenSmooth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory to search\n",
    "search_directory = 'results/hBreast/BayesSpace'\n",
    "\n",
    "# List to store the paths of all .csv files\n",
    "csv_files = []\n",
    "\n",
    "# Walk through the directory\n",
    "for root, dirs, files in os.walk(search_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            clusters = pd.read_csv(os.path.join(root, file))[\"BayesSpace cluster\"]\n",
    "            print(os.path.join(root, file), len(np.unique(clusters.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
