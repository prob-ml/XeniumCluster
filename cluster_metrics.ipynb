{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from importlib import reload\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"hBreast\"\n",
    "models = [\"BayXenSmooth\", \"Leiden\", \"Louvain\", \"K-Means\", \"K-Means_No_Spatial\", \"Hierarchical\", \"Hierarchical_No_Spatial\", \"BayesSpace\"]\n",
    "resolutions = [0.75]\n",
    "spot_sizes = [100, 75, 50]\n",
    "K_values = [17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayXenSmooth Hyperparameters\n",
    "BayXenSmooth_PCs = [3, 5, 10, 25]\n",
    "BayesSpace_PCs = [3, 5, 10, 15, 25]\n",
    "neighborhood_sizes = [1,2,3,4,5]\n",
    "sample_for_assignment = False\n",
    "concentration_amp = 1.0\n",
    "spatial_norms = [0.05, 0.1]\n",
    "aggs = [\"sum\", \"mean\", \"weighted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .gz file\n",
    "file_path = f'data/{dataset_name}/transcripts.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file into a DataFrame\n",
    "df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# drop cells without ids\n",
    "df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "# drop blanks and controls\n",
    "df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Metric Implementations\n",
    "\n",
    "- Variation Index (TODO) If we want to compare competing methods clustering with our clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morans_i_cluster_similarity(clustering, locations, clusters):\n",
    "    print(\"Starting Moran's I Calculation.\")\n",
    "    moran_clusters = ad.AnnData(locations)\n",
    "    sc.pp.neighbors(moran_clusters, n_pcs=0, n_neighbors=100)\n",
    "    print(\"Neighbors calculated.\")\n",
    "\n",
    "    cluster_labels = clusters.values\n",
    "    # Calculate Moran's I for the binary presence of each cluster\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    morans_i_results = {}\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_indicator = (cluster_labels == cluster).astype(int)\n",
    "        morans_i = sc.metrics.morans_i(moran_clusters, vals=cluster_indicator)\n",
    "        morans_i_results[cluster] = morans_i\n",
    "\n",
    "    print(\"Done!\")\n",
    "    return np.mean(list(morans_i_results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gearys_c_cluster_similarity(clustering, locations, clusters):\n",
    "    print(\"Starting Gearys's C Calculation.\")\n",
    "    gearys_clusters = ad.AnnData(locations)\n",
    "    sc.pp.neighbors(gearys_clusters, n_pcs=0, n_neighbors=100)\n",
    "    print(\"Neighbors calculated.\")\n",
    "\n",
    "    cluster_labels = clusters.values\n",
    "    # Calculate Gearys C for the binary presence of each cluster\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    gearys_c_results = {}\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_indicator = (cluster_labels == cluster).astype(int)\n",
    "        gearys_c = sc.metrics.gearys_c(gearys_clusters, vals=cluster_indicator)\n",
    "        gearys_c_results[cluster] = gearys_c\n",
    "\n",
    "    print(\"Done!\")\n",
    "    return np.mean(list(gearys_c_results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, directory, metric_name):\n",
    "    with jsonlines.open(f\"{directory}/{metric_name}.jsonl\", mode='w') as writer:\n",
    "        try:\n",
    "            for key, value in results.items():\n",
    "                writer.write({key: value})\n",
    "        except AttributeError: # b/c it's not a dictionary so .items() fails\n",
    "            writer.write(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Silhouette Score (and other metrics of note.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for spot_size in spot_sizes:\n",
    "#     clustering = XeniumCluster(data=df_transcripts, dataset_name=dataset_name)\n",
    "#     clustering.set_spot_size(spot_size)\n",
    "#     clustering.create_spot_data(third_dim=False, save_data=True)\n",
    "#     locations = clustering.xenium_spot_data.obs[[\"row\", \"col\"]]\n",
    "#     for model in models:\n",
    "#         for K in K_values:\n",
    "#             if model in [\"Leiden\", \"Louvain\"]:\n",
    "#                 for resolution in resolutions:\n",
    "#                     clusters = pd.read_csv(f\"results/{dataset_name}/{model}/{resolution}/clusters/{spot_size}/clusters_RES={resolution}.csv\")[f\"{model} cluster\"]\n",
    "#                     save_results(silhouette_score(locations, clusters), dataset_name, model, \"silhouette_score\", spot_size, resolution=resolution)\n",
    "#                     save_results(morans_i_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"morans_i\", spot_size, resolution=resolution)\n",
    "#                     save_results(gearys_c_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"gearys_c\", spot_size, resolution=resolution)\n",
    "#             elif model == \"BayXenSmooth\":\n",
    "#                 min_expressions_per_spot = 10\n",
    "#                 clustering.xenium_spot_data = clustering.xenium_spot_data[clustering.xenium_spot_data.X.sum(axis=1) > min_expressions_per_spot]\n",
    "#                 for neighborhood_size in neighborhood_sizes:\n",
    "#                     clusters = pd.read_csv(f\"results/{dataset_name}/{model}/clusters/PCA/{BayXenSmooth_PCs}/KMEANSINIT=True/NEIGHBORSIZE={neighborhood_size}/NUMCLUSTERS={K}/SPATIALINIT=True/SAMPLEFORASSIGNMENT={sample_for_assignment}/SPATIALNORM={spatial_norm}/SPATIALPRIORMULT={concentration_amp}/SPOTSIZE={spot_size}/AGG={agg}/clusters_K={K}.csv\")[f\"{model} cluster\"]\n",
    "#                     save_results(silhouette_score(locations, clusters), dataset_name, model, \"silhouette_score\", spot_size, K=K)\n",
    "#                     save_results(morans_i_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"morans_i\", spot_size, K=K, sample_for_assignment=sample_for_assignment)\n",
    "#                     save_results(gearys_c_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"gearys_c\", spot_size, K=K, sample_for_assignment=sample_for_assignment)\n",
    "#             else:\n",
    "#                 clusters = pd.read_csv(f\"results/{dataset_name}/{model}/{K}/clusters/{spot_size}/clusters_K={K}.csv\")[f\"{model} cluster\"]\n",
    "#                 save_results(silhouette_score(locations, clusters), dataset_name, model, \"silhouette_score\", spot_size, K=K)\n",
    "#                 save_results(morans_i_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"morans_i\", spot_size, K=K)\n",
    "#                 save_results(gearys_c_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"gearys_c\", spot_size, K=K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marker Gene Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKER_GENES = [\"BANK1\", \"CEACAM6\", \"FASN\", \"FGL2\", \"IL7R\", \"KRT6B\", \"POSTN\", \"TCIM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_morans_i(clustering, moran_clusters, clusters, num_neighbors=100, marker_genes=MARKER_GENES, print_output=False):\n",
    "\n",
    "    # Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "    cluster_labels = clusters.values\n",
    "    same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "    moran_clusters.obsp[\"adjacency\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "\n",
    "    # Calculate Moran's I for the genes\n",
    "    morans_i = sc.metrics.morans_i(moran_clusters.obsp[\"adjacency\"], vals=clustering.xenium_spot_data.X.T)\n",
    "\n",
    "    morans_i_dict = dict(zip(clustering.xenium_spot_data.var.index, morans_i))\n",
    "\n",
    "    # Print the number of non-zero adjacencies\n",
    "    if print_output:\n",
    "        num_nonzero = moran_clusters.obsp[\"adjacency\"].getnnz()\n",
    "        print(f\"Number of non-zero adjacencies: {num_nonzero}\")\n",
    "        for gene in marker_genes:\n",
    "            print(num_neighbors, gene, morans_i_dict[gene])\n",
    "\n",
    "    return morans_i_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_gearys_c(clustering, gearys_clusters, clusters, num_neighbors=100):\n",
    "\n",
    "    # Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "    cluster_labels = clusters.values\n",
    "    same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "    gearys_clusters.obsp[\"adjacency\"] = gearys_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "    print(\"Connectivities formed.\")\n",
    "\n",
    "    # Calculate Geary's C for the genes\n",
    "    gearys_c= sc.metrics.gearys_c(gearys_clusters.obsp[\"adjacency\"], vals=clustering.xenium_spot_data.X.T)\n",
    "\n",
    "    gearys_c_dict = dict(zip(clustering.xenium_spot_data.var.index, gearys_c))\n",
    "\n",
    "    return gearys_c_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"BayesSpace\"]\n",
    "num_neighboring_spots = [100]\n",
    "spot_sizes = [50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roko/.cache/pypoetry/virtualenvs/xenium-1YUjn3qu-py3.10/lib/python3.10/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/home/roko/.cache/pypoetry/virtualenvs/xenium-1YUjn3qu-py3.10/lib/python3.10/site-packages/anndata/utils.py:292: UserWarning: X converted to numpy array with dtype float64\n",
      "  warnings.warn(f\"{name} converted to numpy array with dtype {arr.dtype}\")\n",
      "/home/roko/.cache/pypoetry/virtualenvs/xenium-1YUjn3qu-py3.10/lib/python3.10/site-packages/anndata/utils.py:292: UserWarning: X converted to numpy array with dtype float64\n",
      "  warnings.warn(f\"{name} converted to numpy array with dtype {arr.dtype}\")\n",
      "/home/roko/.cache/pypoetry/virtualenvs/xenium-1YUjn3qu-py3.10/lib/python3.10/site-packages/anndata/utils.py:292: UserWarning: X converted to numpy array with dtype float64\n",
      "  warnings.warn(f\"{name} converted to numpy array with dtype {arr.dtype}\")\n",
      "/home/roko/.cache/pypoetry/virtualenvs/xenium-1YUjn3qu-py3.10/lib/python3.10/site-packages/anndata/utils.py:292: UserWarning: X converted to numpy array with dtype float64\n",
      "  warnings.warn(f\"{name} converted to numpy array with dtype {arr.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "for spot_size in spot_sizes:\n",
    "    clustering = XeniumCluster(data=df_transcripts, dataset_name=dataset_name)\n",
    "    clustering.set_spot_size(spot_size)\n",
    "    clustering.create_spot_data(third_dim=False, save_data=True)\n",
    "    locations = clustering.xenium_spot_data.obs[[\"row\", \"col\"]]\n",
    "    moran_clusters = ad.AnnData(locations)\n",
    "    gearys_clusters = ad.AnnData(locations)\n",
    "    for model in models:\n",
    "        for neighboring_spots in num_neighboring_spots:\n",
    "            \n",
    "            moran_clusters = ad.AnnData(locations)\n",
    "            sc.pp.neighbors(moran_clusters, n_pcs=0, n_neighbors=neighboring_spots)\n",
    "            gearys_clusters = ad.AnnData(locations)\n",
    "            sc.pp.neighbors(gearys_clusters, n_pcs=0, n_neighbors=neighboring_spots)\n",
    "\n",
    "            # Define the directory where the results are stored\n",
    "            results_dir = f\"results/hBreast/{model}\"\n",
    "\n",
    "            # Loop through all subdirectories in the results directory\n",
    "            for root, dirs, files in os.walk(results_dir):\n",
    "                for file in files:\n",
    "                    # Check if the file is named morans_i_by_gene.json\n",
    "                    if \"clusters_K=17\" in file and \".csv\" in file and str(spot_size) in root:\n",
    "\n",
    "                        clusters = pd.read_csv(os.path.join(root, file))[f\"{model} cluster\"]\n",
    "                        save_results(gene_morans_i(clustering, moran_clusters, clusters, num_neighbors=100), root, \"morans_i_by_gene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayXenSmooth Best Moran's I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the directory where the results are stored\n",
    "results_dir = \"results/hBreast/BayXenSmooth\"\n",
    "\n",
    "# Loop through all subdirectories in the results directory\n",
    "morans_i_dict = {}\n",
    "for gene_name in MARKER_GENES:\n",
    "    current_max_expression = 0\n",
    "    current_best_wss = float('inf')\n",
    "    for root, dirs, files in os.walk(results_dir):\n",
    "        for file in files:\n",
    "            # Check if the file is named morans_i_by_gene.json\n",
    "            if file == \"morans_i_by_gene.jsonl\":\n",
    "                # Construct the full path to the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Open and read the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    # Load the JSON data\n",
    "                    data = [line for line in jsonlines.Reader(f)]\n",
    "                    # Print the data to verify it's been loaded\n",
    "                    morans_i = [x for x in data if gene_name in x]\n",
    "                    if morans_i[0][gene_name] > current_max_expression and \"SPOTSIZE=50\" in file_path:# and \"K-Means\" in file_path:\n",
    "                        current_max_filepath = file_path\n",
    "                        current_max_expression = morans_i[0][gene_name]\n",
    "                        wss_root = root\n",
    "                        with open(wss_root.replace(\"clusters\", \"wss\") + \"/wss.json\") as f:\n",
    "                            current_best_wss = sum(json.load(f).values()) / 1_000_000\n",
    "    morans_i_dict[gene_name] = current_max_expression, current_max_filepath, current_best_wss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BANK1': (0.9858294031893302,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/5/INIT=K-Means/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/MU_Q=1.0/SIGMA_Q=0.25/LOGITS_Q=0.1/morans_i_by_gene.jsonl',\n",
       "  2.8652659863275978),\n",
       " 'CEACAM6': (0.4046276968017171,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/3/INIT=mclust/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=False/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/MU_Q=0.1/SIGMA_Q=0.25/LOGITS_Q=1.0/morans_i_by_gene.jsonl',\n",
       "  nan),\n",
       " 'FASN': (1.134218948558054,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/15/INIT=K-Means/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/MU_Q=0.1/SIGMA_Q=0.25/LOGITS_Q=1.0/morans_i_by_gene.jsonl',\n",
       "  2.9530559317153955),\n",
       " 'FGL2': (0.5020470507342425,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/15/INIT=K-Means/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=1.0/SIGMA_PRIOR=0.25/MU_Q=0.1/SIGMA_Q=0.25/LOGITS_Q=0.1/morans_i_by_gene.jsonl',\n",
       "  2.789074343586274),\n",
       " 'IL7R': (0.8596927271378607,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/15/INIT=K-Means/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/MU_Q=1.0/SIGMA_Q=0.25/LOGITS_Q=1.0/morans_i_by_gene.jsonl',\n",
       "  2.9028273167398764),\n",
       " 'KRT6B': (0.6350048371323994,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/3/INIT=K-Means/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/MU_Q=0.1/SIGMA_Q=0.25/LOGITS_Q=1.0/morans_i_by_gene.jsonl',\n",
       "  2.831480371994888),\n",
       " 'POSTN': (0.5503350523495066,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/15/INIT=Leiden/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=1.0/SIGMA_PRIOR=0.25/MU_Q=0.1/SIGMA_Q=0.25/LOGITS_Q=1.0/morans_i_by_gene.jsonl',\n",
       "  2.5127125639610077),\n",
       " 'TCIM': (0.7056727115728926,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=Leiden/NEIGHBORSIZE=1/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=True/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/MU_Q=0.1/SIGMA_Q=0.25/LOGITS_Q=0.1/morans_i_by_gene.jsonl',\n",
       "  2.513665772244832)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morans_i_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Moran's I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/hBreast/Hierarchical/17/morans_i_by_gene/50/wss.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m                     current_max_expression \u001b[38;5;241m=\u001b[39m morans_i[\u001b[38;5;241m0\u001b[39m][gene_name]\n\u001b[1;32m     30\u001b[0m                     wss_root \u001b[38;5;241m=\u001b[39m root\n\u001b[0;32m---> 31\u001b[0m                     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwss_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclusters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/wss.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     32\u001b[0m                         current_best_wss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(json\u001b[38;5;241m.\u001b[39mload(f)\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1_000_000\u001b[39m\n\u001b[1;32m     33\u001b[0m morans_i_dict[gene_name] \u001b[38;5;241m=\u001b[39m current_max_expression, current_max_filepath, current_best_wss\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/xenium-1YUjn3qu-py3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/hBreast/Hierarchical/17/morans_i_by_gene/50/wss.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "MARKER_GENES = [\"BANK1\", \"CEACAM6\", \"FASN\", \"FGL2\", \"IL7R\", \"KRT6B\", \"POSTN\", \"TCIM\"]\n",
    "\n",
    "# Define the directory where the results are stored\n",
    "results_dir = \"results/hBreast\"\n",
    "\n",
    "# Loop through all subdirectories in the results directory\n",
    "morans_i_dict = {}\n",
    "for gene_name in MARKER_GENES:\n",
    "    current_max_expression = 0\n",
    "    current_best_wss = float('inf')\n",
    "    for root, dirs, files in os.walk(results_dir):\n",
    "        for file in files:\n",
    "            # Check if the file is named morans_i_by_gene.json\n",
    "            if file == \"morans_i_by_gene.jsonl\":\n",
    "                # Construct the full path to the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Open and read the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    # Load the JSON data\n",
    "                    data = [line for line in jsonlines.Reader(f)]\n",
    "                    # Print the data to verify it's been loaded\n",
    "                    morans_i = [x for x in data if gene_name in x]\n",
    "                    unused_runs = [\"Leiden/2.0\", \"Leiden/1.5\", \"Louvain/2.0\", \"Louvain/1.5\"]\n",
    "                    if morans_i[0][gene_name] > current_max_expression and \"50/\" in file_path and not any(x in file_path for x in unused_runs):\n",
    "                        current_max_filepath = file_path\n",
    "                        current_max_expression = morans_i[0][gene_name]\n",
    "                        wss_root = root\n",
    "                        with open(wss_root.replace(\"clusters\", \"wss\") + \"/wss.json\") as f:\n",
    "                            current_best_wss = sum(json.load(f).values()) / 1_000_000\n",
    "    morans_i_dict[gene_name] = current_max_expression, current_max_filepath, current_best_wss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BANK1': (1.448704617750098,\n",
       "  'results/hBreast/K-Means/17/morans_i_by_gene/50/morans_i_by_gene.jsonl',\n",
       "  2.513665772244832),\n",
       " 'CEACAM6': (0.44061166528173595,\n",
       "  'results/hBreast/Hierarchical/17/morans_i_by_gene/50/morans_i_by_gene.jsonl',\n",
       "  2.513665772244832),\n",
       " 'FASN': (1.2764190262433492,\n",
       "  'results/hBreast/mclust/5/17/morans_i_by_gene/50/morans_i_by_gene.jsonl',\n",
       "  2.513665772244832),\n",
       " 'FGL2': (0.6541047360674477,\n",
       "  'results/hBreast/K-Means/17/morans_i_by_gene/50/morans_i_by_gene.jsonl',\n",
       "  2.513665772244832),\n",
       " 'IL7R': (1.2555361612748626,\n",
       "  'results/hBreast/K-Means/17/morans_i_by_gene/50/morans_i_by_gene.jsonl',\n",
       "  2.513665772244832),\n",
       " 'KRT6B': (0.9633136956155999,\n",
       "  'results/hBreast/K-Means/17/morans_i_by_gene/50/morans_i_by_gene.jsonl',\n",
       "  2.513665772244832),\n",
       " 'POSTN': (0.6150417644630521,\n",
       "  'results/hBreast/Leiden/0.75/morans_i_by_gene/50/morans_i_by_gene.jsonl',\n",
       "  2.513665772244832),\n",
       " 'TCIM': (0.8340732269715522,\n",
       "  'results/hBreast/Leiden/0.75/morans_i_by_gene/50/morans_i_by_gene.jsonl',\n",
       "  2.513665772244832)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morans_i_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Methods Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/hBreast/BayesSpace/25/17/wss/mclust/50/wss.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m                     current_max_expression \u001b[38;5;241m=\u001b[39m morans_i[\u001b[38;5;241m0\u001b[39m][gene_name]\n\u001b[1;32m     30\u001b[0m                     wss_root \u001b[38;5;241m=\u001b[39m root\n\u001b[0;32m---> 31\u001b[0m                     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwss_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclusters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/wss.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     32\u001b[0m                         current_best_wss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(json\u001b[38;5;241m.\u001b[39mload(f)\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1_000_000\u001b[39m\n\u001b[1;32m     33\u001b[0m morans_i_dict[gene_name] \u001b[38;5;241m=\u001b[39m current_max_expression, current_max_filepath, current_best_wss\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/xenium-1YUjn3qu-py3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/hBreast/BayesSpace/25/17/wss/mclust/50/wss.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the directory where the results are stored\n",
    "# results_dirs = [\"results/hBreast/BayXenSmooth\", \"results/hBreast/BayesSpace\"]\n",
    "results_dirs = [\"results/hBreast/BayesSpace\"]\n",
    "\n",
    "# Loop through all subdirectories in the results directory\n",
    "morans_i_dict = {}\n",
    "for gene_name in MARKER_GENES:\n",
    "    current_max_expression = 0\n",
    "    current_best_wss = float('inf')\n",
    "    for dir in results_dirs:\n",
    "        for root, dirs, files in os.walk(dir):\n",
    "            for file in files:\n",
    "                # Check if the file is named morans_i_by_gene.json\n",
    "                if file == \"morans_i_by_gene.jsonl\":\n",
    "                    # Construct the full path to the file\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    # Open and read the file\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        # Load the JSON data\n",
    "                        data = [line for line in jsonlines.Reader(f)]\n",
    "                        # Print the data to verify it's been loaded\n",
    "                        morans_i = [x for x in data if gene_name in x]\n",
    "                        unused_runs = [\"Leiden/2.0\", \"Leiden/1.5\", \"Louvain/2.0\", \"Louvain/1.5\"]\n",
    "                        if morans_i[0][gene_name] > current_max_expression and \"50/\" in file_path and not any(x in file_path for x in unused_runs):\n",
    "                            current_max_filepath = file_path\n",
    "                            current_max_expression = morans_i[0][gene_name]\n",
    "                            wss_root = root\n",
    "                            with open(wss_root.replace(\"clusters\", \"wss\") + \"/wss.json\") as f:\n",
    "                                current_best_wss = sum(json.load(f).values()) / 1_000_000\n",
    "        morans_i_dict[gene_name] = current_max_expression, current_max_filepath, current_best_wss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morans_i_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows.shape, bank1_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Get the index of the gene \n",
    "\n",
    "gene = \"BANK1\"\n",
    "\n",
    "bank1_index = clustering.xenium_spot_data.var.index.get_loc(gene)\n",
    "\n",
    "# Extract the data for \"BANK1\"\n",
    "bank1_data = torch.tensor(clustering.xenium_spot_data.X[:, bank1_index])\n",
    "\n",
    "rows = clustering.xenium_spot_data.obs[\"row\"].astype(int)\n",
    "columns = clustering.xenium_spot_data.obs[\"col\"].astype(int)\n",
    "\n",
    "num_rows = max(rows) + 1\n",
    "num_cols = max(columns) + 1\n",
    "\n",
    "marker_grid = torch.zeros(num_rows, num_cols, dtype=float)\n",
    "\n",
    "marker_grid[rows, columns] = bank1_data\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(marker_grid, origin='lower')  # Invert the y-axis by setting origin to 'upper'\n",
    "plt.title(f'Expression of {gene}')\n",
    "plt.xlabel('Row')\n",
    "plt.ylabel('Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(clustering.xenium_spot_data.var[\"BANK1\"], cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_per_side = 100\n",
    "\n",
    "print(\"Starting Moran's I Calculation.\")\n",
    "moran_clusters = ad.AnnData(locations)\n",
    "sc.pp.neighbors(moran_clusters, n_pcs=0, n_neighbors=100)\n",
    "print(\"Neighbors calculated.\")\n",
    "\n",
    "connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "# connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()\n",
    "\n",
    "# Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "cluster_labels = clusters.values\n",
    "same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "print(moran_clusters.obsp[\"connectivities\"].shape, same_cluster.shape)\n",
    "moran_clusters.obsp[\"connectivities\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "print(\"Connectivities formed.\")\n",
    "\n",
    "# Calculate Moran's I for the genes\n",
    "morans_i = sc.metrics.morans_i(moran_clusters, vals=clustering.xenium_spot_data.X.T)\n",
    "\n",
    "morans_i_dict = dict(zip(clustering.xenium_spot_data.var.index, morans_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_per_side = 100\n",
    "\n",
    "print(\"Starting Moran's I Calculation.\")\n",
    "moran_clusters = ad.AnnData(locations)\n",
    "sc.pp.neighbors(moran_clusters, n_pcs=0, n_neighbors=100)\n",
    "print(\"Neighbors calculated.\")\n",
    "\n",
    "connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "# connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()\n",
    "\n",
    "# Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "cluster_labels = clusters.values\n",
    "same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "print(moran_clusters.obsp[\"connectivities\"].shape, same_cluster.shape)\n",
    "moran_clusters.obsp[\"connectivities\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "print(\"Connectivities formed.\")\n",
    "\n",
    "# Calculate Moran's I for the genes\n",
    "morans_i = sc.metrics.morans_i(moran_clusters, vals=clustering.xenium_spot_data.X.T)\n",
    "\n",
    "morans_i_dict = dict(zip(clustering.xenium_spot_data.var.index, morans_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first 10x10 submatrix of the connectivities matrix\n",
    "connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "# connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spots_per_side = 100\n",
    "\n",
    "# Extract the first 10x10 submatrix of the connectivities matrix\n",
    "# connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check of Clusters and Moran's I Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "num_clusters = K\n",
    "\n",
    "rows = locations[\"row\"].astype(int)\n",
    "columns = locations[\"col\"].astype(int)\n",
    "\n",
    "num_rows = max(rows) + 1\n",
    "num_cols = max(columns) + 1\n",
    "\n",
    "cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.long)\n",
    "\n",
    "cluster_grid[rows, columns] = torch.tensor(clusters) + 1\n",
    "\n",
    "colors = plt.cm.get_cmap('viridis', num_clusters + 1)\n",
    "\n",
    "colormap_colors = np.vstack(([[1, 1, 1, 1]], colors(np.linspace(0, 1, num_clusters))))\n",
    "colormap = ListedColormap(colormap_colors)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cluster_grid, cmap=colormap, interpolation='nearest', origin='lower')\n",
    "plt.colorbar(ticks=range(num_clusters + 1), label='Cluster Values')\n",
    "plt.title('Prior Cluster Assignment with BayXenSmooth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory to search\n",
    "search_directory = 'results/hBreast/BayesSpace'\n",
    "\n",
    "# List to store the paths of all .csv files\n",
    "csv_files = []\n",
    "\n",
    "# Walk through the directory\n",
    "for root, dirs, files in os.walk(search_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            clusters = pd.read_csv(os.path.join(root, file))[\"BayesSpace cluster\"]\n",
    "            print(os.path.join(root, file), len(np.unique(clusters.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
