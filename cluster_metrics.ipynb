{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import norm\n",
    "\n",
    "from importlib import reload\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"hBreast\"\n",
    "models = [\"Leiden\", \"Louvain\", \"K-Means\", \"Hierarchical_No_Spatial\", \"mclust\"]\n",
    "resolutions = [0.75]\n",
    "spot_sizes = [100, 75, 50]\n",
    "K_values = [17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayXenSmooth Hyperparameters\n",
    "BayXenSmooth_PCs = [3, 5, 10, 25]\n",
    "BayesSpace_PCs = [3, 5, 10, 15, 25]\n",
    "neighborhood_sizes = [1,2,3,4,5]\n",
    "sample_for_assignment = False\n",
    "concentration_amp = 1.0\n",
    "spatial_norms = [0.05, 0.1]\n",
    "aggs = [\"sum\", \"mean\", \"weighted\"]\n",
    "num_neighboring_spots = [50, 100, 200, 400]\n",
    "kernels = ['umap', 'naive_distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .gz file\n",
    "file_path = f'data/{dataset_name}/transcripts.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file into a DataFrame\n",
    "df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# drop cells without ids\n",
    "df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "# drop blanks and controls\n",
    "df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Metric Implementations\n",
    "\n",
    "- Variation Index (TODO) If we want to compare competing methods clustering with our clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morans_i_cluster_similarity(clustering, locations, clusters, num_neighbors=100, kernel='umap', p=1, print_output=False):\n",
    "    \n",
    "    moran_clusters = ad.AnnData(locations)\n",
    "    cluster_labels = clusters.values\n",
    "\n",
    "    if kernel in ['umap', 'gauss']:\n",
    "        sc.pp.neighbors(moran_clusters, n_neighbors=num_neighbors, use_rep='X', n_pcs=0, method=kernel)\n",
    "    elif kernel == 'naive_distance':\n",
    "        def naive_distance(x, p=1):\n",
    "            return 1 / ((1 + x)**(1/p))\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=num_neighbors).fit(moran_clusters.X)\n",
    "        distances, indices = nbrs.kneighbors(moran_clusters.X)\n",
    "        connectivities = csr_matrix((moran_clusters.shape[0], moran_clusters.shape[0]))\n",
    "        connectivities[np.arange(len(indices))[:, None], indices] = naive_distance(distances, p)\n",
    "        moran_clusters.obsp[\"connectivities\"] = connectivities\n",
    "\n",
    "    # Calculate Moran's I for the binary presence of each cluster\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    morans_i_results = {}\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_indicator = (cluster_labels == cluster).astype(int)\n",
    "        morans_i = sc.metrics.morans_i(moran_clusters.obsp[\"connectivities\"], vals=cluster_indicator)\n",
    "        morans_i_results[cluster] = morans_i\n",
    "\n",
    "    return np.mean(list(morans_i_results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gearys_c_cluster_similarity(clustering, locations, clusters, num_neighbors=100, kernel='umap', p=1, print_output=False):\n",
    "\n",
    "    gearys_clusters = ad.AnnData(locations)\n",
    "\n",
    "    cluster_labels = clusters.values\n",
    "    # Calculate Gearys C for the binary presence of each cluster\n",
    "    if kernel in ['umap', 'gauss']:\n",
    "        sc.pp.neighbors(gearys_clusters, n_neighbors=num_neighbors, use_rep='X', n_pcs=0, method=kernel)\n",
    "    elif kernel == 'naive_distance':\n",
    "        def naive_distance(x, p=1):\n",
    "            return 1 / ((1 + x)**(1/p))\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=num_neighbors).fit(gearys_clusters.X)\n",
    "        distances, indices = nbrs.kneighbors(gearys_clusters.X)\n",
    "        connectivities = csr_matrix((gearys_clusters.shape[0], gearys_clusters.shape[0]))\n",
    "        connectivities[np.arange(len(indices))[:, None], indices] = naive_distance(distances, p)\n",
    "        gearys_clusters.obsp[\"connectivities\"] = connectivities\n",
    "\n",
    "    # Calculate Moran's I for the binary presence of each cluster\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    gearys_c_results = {}\n",
    "    for cluster in unique_clusters:\n",
    "        cluster_indicator = (cluster_labels == cluster).astype(int)\n",
    "        gearys_c = sc.metrics.gearys_c(gearys_clusters, vals=cluster_indicator)\n",
    "        gearys_c_results[cluster] = gearys_c\n",
    "\n",
    "    return np.mean(list(gearys_c_results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, directory, metric_name, specification=None):\n",
    "    subdirectory = f\"{specification}\" if specification else \"\"\n",
    "    full_path = f\"{directory}/{subdirectory}\"\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(full_path, exist_ok=True)\n",
    "    \n",
    "    with jsonlines.open(f\"{full_path}/{metric_name}.jsonl\", mode='w') as writer:\n",
    "        try:\n",
    "            for key, value in results.items():\n",
    "                writer.write({key: value})\n",
    "        except AttributeError: # b/c it's not a dictionary so .items() fails\n",
    "            writer.write(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Silhouette Score (and other metrics of note.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "\n",
    "with io.capture_output():\n",
    "    for spot_size in spot_sizes:\n",
    "        print(spot_size)\n",
    "        clustering = XeniumCluster(data=df_transcripts, dataset_name=dataset_name)\n",
    "        clustering.set_spot_size(spot_size)\n",
    "        clustering.create_spot_data(third_dim=False, save_data=True)\n",
    "        locations = clustering.xenium_spot_data.obs[[\"row\", \"col\"]]\n",
    "        for K in K_values:\n",
    "            for model in models:\n",
    "                results_dir = f\"results/hBreast/{model}\"\n",
    "                for root, dirs, files in os.walk(results_dir):\n",
    "                    for file in files:\n",
    "                        print(os.path.join(root, file), (file == f\"clusters_K={K}.csv\" or (file.endswith(\".csv\") and \"clusters_RES\" in file)) and f\"/{spot_size}/\" in root)\n",
    "                        # Check if the file is named morans_i_by_gene.json\n",
    "                        if model == \"BayXenSmooth\":\n",
    "                            if (file == f\"clusters_K={K}.csv\" or (file.endswith(\".csv\") and \"clusters_RES\" in file)) and f\"/SPOTSIZE={spot_size}/\" in os.path.join(root, file):\n",
    "                                for neighboring_spots in num_neighboring_spots:\n",
    "                                    for kernel in kernels:\n",
    "                                        clusters = pd.read_csv(os.path.join(root, file))[f\"{model} cluster\"]\n",
    "                                        save_results(morans_i_cluster_similarity(clustering, locations, clusters, num_neighbors=neighboring_spots, kernel=kernel), root, \"morans_i\", specification=f\"{kernel}/{neighboring_spots}\")\n",
    "                                        save_results(gearys_c_cluster_similarity(clustering, locations, clusters, num_neighbors=neighboring_spots, kernel=kernel), root, \"gearys_c\", specification=f\"{kernel}/{neighboring_spots}\")\n",
    "                                        save_results(silhouette_score(locations, clusters), root, \"silhouette_score\")\n",
    "                        else:\n",
    "                            if (file == f\"clusters_K={K}.csv\" or (file.endswith(\".csv\") and \"clusters_RES\" in file)) and f\"/{spot_size}/\" in os.path.join(root, file):\n",
    "                                for neighboring_spots in num_neighboring_spots:\n",
    "                                    for kernel in kernels:\n",
    "                                        clusters = pd.read_csv(os.path.join(root, file))[f\"{model} cluster\"]\n",
    "                                        save_results(morans_i_cluster_similarity(clustering, locations, clusters, num_neighbors=neighboring_spots, kernel=kernel), root, \"morans_i\", specification=f\"{kernel}/{neighboring_spots}\")\n",
    "                                        save_results(gearys_c_cluster_similarity(clustering, locations, clusters, num_neighbors=neighboring_spots, kernel=kernel), root, \"gearys_c\", specification=f\"{kernel}/{neighboring_spots}\")\n",
    "                                        save_results(silhouette_score(locations, clusters), root, \"silhouette_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for spot_size in spot_sizes:\n",
    "#     clustering = XeniumCluster(data=df_transcripts, dataset_name=dataset_name)\n",
    "#     clustering.set_spot_size(spot_size)\n",
    "#     clustering.create_spot_data(third_dim=False, save_data=True)\n",
    "#     locations = clustering.xenium_spot_data.obs[[\"row\", \"col\"]]\n",
    "#     for model in models:\n",
    "#         for K in K_values:\n",
    "#             if model in [\"Leiden\", \"Louvain\"]:\n",
    "#                 for resolution in resolutions:\n",
    "#                     clusters = pd.read_csv(f\"results/{dataset_name}/{model}/{resolution}/clusters/{spot_size}/clusters_RES={resolution}.csv\")[f\"{model} cluster\"]\n",
    "#                     save_results(silhouette_score(locations, clusters), dataset_name, model, \"silhouette_score\", spot_size, resolution=resolution)\n",
    "#                     save_results(morans_i_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"morans_i\", spot_size, resolution=resolution)\n",
    "#                     save_results(gearys_c_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"gearys_c\", spot_size, resolution=resolution)\n",
    "#             elif model == \"BayXenSmooth\":\n",
    "#                 min_expressions_per_spot = 10\n",
    "#                 clustering.xenium_spot_data = clustering.xenium_spot_data[clustering.xenium_spot_data.X.sum(axis=1) > min_expressions_per_spot]\n",
    "#                 for neighborhood_size in neighborhood_sizes:\n",
    "#                     clusters = pd.read_csv(f\"results/{dataset_name}/{model}/clusters/PCA/{BayXenSmooth_PCs}/KMEANSINIT=True/NEIGHBORSIZE={neighborhood_size}/NUMCLUSTERS={K}/SPATIALINIT=True/SAMPLEFORASSIGNMENT={sample_for_assignment}/SPATIALNORM={spatial_norm}/SPATIALPRIORMULT={concentration_amp}/SPOTSIZE={spot_size}/AGG={agg}/clusters_K={K}.csv\")[f\"{model} cluster\"]\n",
    "#                     save_results(silhouette_score(locations, clusters), dataset_name, model, \"silhouette_score\", spot_size, K=K)\n",
    "#                     save_results(morans_i_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"morans_i\", spot_size, K=K, sample_for_assignment=sample_for_assignment)\n",
    "#                     save_results(gearys_c_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"gearys_c\", spot_size, K=K, sample_for_assignment=sample_for_assignment)\n",
    "#             else:\n",
    "#                 clusters = pd.read_csv(f\"results/{dataset_name}/{model}/{K}/clusters/{spot_size}/clusters_K={K}.csv\")[f\"{model} cluster\"]\n",
    "#                 save_results(silhouette_score(locations, clusters), dataset_name, model, \"silhouette_score\", spot_size, K=K)\n",
    "#                 save_results(morans_i_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"morans_i\", spot_size, K=K)\n",
    "#                 save_results(gearys_c_cluster_similarity(clustering, locations, clusters), dataset_name, model, \"gearys_c\", spot_size, K=K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marker Gene Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKER_GENES = [\"BANK1\", \"CEACAM6\", \"FASN\", \"FGL2\", \"IL7R\", \"KRT6B\", \"POSTN\", \"TCIM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_morans_i(clustering, moran_clusters, clusters, num_neighbors=100, kernel='umap', p=1, marker_genes=MARKER_GENES, print_output=False):\n",
    "\n",
    "    # Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "    cluster_labels = clusters.values\n",
    "    same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "\n",
    "    if kernel == 'umap':\n",
    "        sc.pp.neighbors(moran_clusters, n_neighbors=num_neighbors, use_rep='X', n_pcs=0, method=kernel)\n",
    "        moran_clusters.obsp[\"adjacency\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "    elif kernel == 'gauss':\n",
    "        sc.pp.neighbors(moran_clusters, n_neighbors=num_neighbors, use_rep='X', n_pcs=0, method=kernel)\n",
    "        moran_clusters.obsp[\"adjacency\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "    elif kernel == 'naive_distance':\n",
    "        def naive_distance(x, p=1):\n",
    "            return 1 / ((1 + x)**(1/p))\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=num_neighbors).fit(moran_clusters.X)\n",
    "        distances, indices = nbrs.kneighbors(moran_clusters.X)\n",
    "        connectivities = csr_matrix((moran_clusters.shape[0], moran_clusters.shape[0]))\n",
    "        connectivities[np.arange(len(indices))[:, None], indices] = naive_distance(distances, p)\n",
    "        moran_clusters.obsp[\"connectivities\"] = connectivities\n",
    "        moran_clusters.obsp[\"adjacency\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "    elif kernel == 'basic':\n",
    "        moran_clusters.obsp[\"adjacency\"] = csr_matrix(same_cluster)\n",
    "    else:\n",
    "        warnings.warn(f\"Kernel '{kernel}' not implemented. Using 'basic' kernel instead. We recommend 'umap'.\", UserWarning)\n",
    "        kernel = 'basic'\n",
    "        moran_clusters.obsp[\"adjacency\"] = csr_matrix(same_cluster)\n",
    "\n",
    "    # Calculate Moran's I for the genes\n",
    "    morans_i = sc.metrics.morans_i(moran_clusters.obsp[\"adjacency\"], vals=clustering.xenium_spot_data.X.T)\n",
    "    morans_i_dict = dict(zip(clustering.xenium_spot_data.var.index, morans_i))\n",
    "\n",
    "    # Print the number of non-zero adjacencies\n",
    "    if print_output:\n",
    "        num_nonzero = moran_clusters.obsp[\"adjacency\"].getnnz()\n",
    "        print(f\"Number of non-zero adjacencies: {num_nonzero}\")\n",
    "        for gene in marker_genes:\n",
    "            print(num_neighbors, gene, morans_i_dict[gene])\n",
    "\n",
    "    return morans_i_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_gearys_c(clustering, gearys_clusters, clusters, num_neighbors=100):\n",
    "\n",
    "    # Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "    cluster_labels = clusters.values\n",
    "    same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "    gearys_clusters.obsp[\"adjacency\"] = gearys_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "    print(\"Connectivities formed.\")\n",
    "\n",
    "    # Calculate Geary's C for the genes\n",
    "    gearys_c= sc.metrics.gearys_c(gearys_clusters.obsp[\"adjacency\"], vals=clustering.xenium_spot_data.X.T)\n",
    "\n",
    "    gearys_c_dict = dict(zip(clustering.xenium_spot_data.var.index, gearys_c))\n",
    "\n",
    "    return gearys_c_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"BayesSpace\", \"Leiden\", \"Louvain\", \"K-Means\", \"Hierarchical_No_Spatial\", \"mclust\"]\n",
    "num_neighboring_spots = [50, 100, 200, 400]\n",
    "kernels = ['umap']\n",
    "spot_sizes = [50]\n",
    "K = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot_size in spot_sizes:\n",
    "    clustering = XeniumCluster(data=df_transcripts, dataset_name=dataset_name)\n",
    "    clustering.set_spot_size(spot_size)\n",
    "    clustering.create_spot_data(third_dim=False, save_data=True)\n",
    "    locations = clustering.xenium_spot_data.obs[[\"row\", \"col\"]]\n",
    "    moran_clusters = ad.AnnData(locations)\n",
    "    gearys_clusters = ad.AnnData(locations)\n",
    "    for model in models:\n",
    "        print(model)\n",
    "\n",
    "        moran_clusters = ad.AnnData(locations)\n",
    "        gearys_clusters = ad.AnnData(locations)\n",
    "\n",
    "        # Define the directory where the results are stored\n",
    "        results_dir = f\"results/hBreast/{model}\"\n",
    "\n",
    "        # Loop through all subdirectories in the results directory\n",
    "        for root, dirs, files in os.walk(results_dir):\n",
    "            for file in files:\n",
    "                # Check if the file is named morans_i_by_gene.json\n",
    "                if (file == f\"clusters_K={K}.csv\" or (file.endswith(\".csv\") and \"clusters_RES\" in file)) and str(spot_size) in root:\n",
    "                    # print(os.path.join(root, file))\n",
    "                    for neighboring_spots in num_neighboring_spots:\n",
    "                        for kernel in kernels:\n",
    "\n",
    "                            clusters = pd.read_csv(os.path.join(root, file))[f\"{model} cluster\"]\n",
    "                            save_results(gene_morans_i(clustering, moran_clusters, clusters, num_neighbors=neighboring_spots, kernel=kernel, print_output=False), root, \"morans_i_by_gene\", specification=f\"{kernel}/{neighboring_spots}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Method Marker Gene Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where the results are stored\n",
    "results_dir = \"results/hBreast/Leiden\"\n",
    "morans_i_dict = {}\n",
    "marker_gene_ranking_dict = {gene: {\"rank\": float('inf')} for gene in MARKER_GENES}\n",
    "for root, dirs, files in os.walk(results_dir):\n",
    "    for file in files:\n",
    "        # Check if the file is named morans_i_by_gene.json\n",
    "        if file == \"morans_i_by_gene.jsonl\":\n",
    "            used_runs = [\"Leiden/0.75\", \"Louvain/1.0\"]\n",
    "\n",
    "            # Construct the full path to the file\n",
    "            file_path = os.path.join(root, file)\n",
    "            if not any(x in file_path for x in [\"Leiden\", \"Louvain\"]) or any(x in file_path for x in used_runs):\n",
    "                # Open and read the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    # Load the JSON data\n",
    "                    data = [line for line in jsonlines.Reader(f)]\n",
    "                    data = sorted(data, key=lambda x: next(iter(x.values())), reverse=True)\n",
    "                    for i, data_point in enumerate(data):\n",
    "                        gene, morans_i_val = next(iter(data_point.items()))\n",
    "                        if gene in MARKER_GENES:\n",
    "                            if marker_gene_ranking_dict[gene][\"rank\"] > (i + 1):\n",
    "                                marker_gene_ranking_dict[gene][\"rank\"] = (i + 1)\n",
    "                                marker_gene_ranking_dict[gene][\"filepath\"] = file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BANK1': {'rank': 3,\n",
       "  'filepath': 'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i_by_gene.jsonl'},\n",
       " 'CEACAM6': {'rank': 206,\n",
       "  'filepath': 'results/hBreast/Leiden/0.75/clusters/50/umap/400/morans_i_by_gene.jsonl'},\n",
       " 'FASN': {'rank': 14,\n",
       "  'filepath': 'results/hBreast/Leiden/0.75/clusters/50/umap/400/morans_i_by_gene.jsonl'},\n",
       " 'FGL2': {'rank': 145,\n",
       "  'filepath': 'results/hBreast/Leiden/0.75/clusters/50/umap/100/morans_i_by_gene.jsonl'},\n",
       " 'IL7R': {'rank': 14,\n",
       "  'filepath': 'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i_by_gene.jsonl'},\n",
       " 'KRT6B': {'rank': 30,\n",
       "  'filepath': 'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i_by_gene.jsonl'},\n",
       " 'POSTN': {'rank': 123,\n",
       "  'filepath': 'results/hBreast/Leiden/0.75/clusters/50/umap/400/morans_i_by_gene.jsonl'},\n",
       " 'TCIM': {'rank': 71,\n",
       "  'filepath': 'results/hBreast/Leiden/0.75/clusters/50/umap/100/morans_i_by_gene.jsonl'}}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marker_gene_ranking_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayXenSmooth Best Moran's I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where the results are stored\n",
    "results_dir = \"results/hBreast/BayXenSmooth\"\n",
    "\n",
    "# Loop through all subdirectories in the results directory\n",
    "morans_i_dict = {}\n",
    "for gene_name in MARKER_GENES:\n",
    "    current_max_expression = 0\n",
    "    current_best_mpd = float('inf')\n",
    "    for root, dirs, files in os.walk(results_dir):\n",
    "        for file in files:\n",
    "            # Check if the file is named morans_i_by_gene.json\n",
    "            if file == \"morans_i_by_gene.jsonl\":\n",
    "                # Construct the full path to the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Open and read the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    # Load the JSON data\n",
    "                    data = [line for line in jsonlines.Reader(f)]\n",
    "                    # Print the data to verify it's been loaded\n",
    "                    morans_i = [x for x in data if gene_name in x]\n",
    "                    if morans_i[0][gene_name] > current_max_expression and \"SPOTSIZE=50\" in file_path:# and \"K-Means\" in file_path:\n",
    "                        current_max_filepath = file_path\n",
    "                        current_max_expression = morans_i[0][gene_name]\n",
    "                        mpd_root = root\n",
    "                        pattern = r\"(?:umap|naive_distance|gauss|basic)/\\d+\"\n",
    "                        mpd_root = re.sub(pattern, \"\", mpd_root)\n",
    "                        mpd_dir = mpd_root.replace(\"clusters\", \"mpd\")\n",
    "                        try:\n",
    "                            mpd_file = next((f for f in os.listdir(mpd_dir) if f.endswith(\".json\")), None)\n",
    "                            if mpd_file:\n",
    "                                with open(os.path.join(mpd_dir, mpd_file)) as f:\n",
    "                                    mpd_dict = json.load(f)\n",
    "                                    if len(mpd_dict) == K:\n",
    "                                        current_best_mpd = sum(mpd_dict.values()) / 1_000\n",
    "                                    else:\n",
    "                                        current_best_mpd = (sum(mpd_dict.values()) / 1_000, f\"(but K* = {len(mpd_dict)})\")\n",
    "                        except FileNotFoundError:\n",
    "                            print(os.path.join(mpd_dir, mpd_file), \"has missing MPD.\")\n",
    "    morans_i_dict[gene_name] = current_max_expression, current_max_filepath, current_best_mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{50: (0.7146477812460335, 'results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=K-Means/NEIGHBORSIZE=4/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=False/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=1.0/SIGMA_PRIOR=0.25/LOGITS_PRIOR=0.1/LEARN_GLOBAL_VARS=True/umap/50/morans_i.jsonl')}\n",
      "{50: (0.7146477812460335, 'results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=K-Means/NEIGHBORSIZE=4/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=False/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=1.0/SIGMA_PRIOR=0.25/LOGITS_PRIOR=0.1/LEARN_GLOBAL_VARS=True/umap/50/morans_i.jsonl'), 75: (-inf, '')}\n",
      "{50: (0.7146477812460335, 'results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=K-Means/NEIGHBORSIZE=4/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=False/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=1.0/SIGMA_PRIOR=0.25/LOGITS_PRIOR=0.1/LEARN_GLOBAL_VARS=True/umap/50/morans_i.jsonl'), 75: (-inf, ''), 100: (-inf, '')}\n",
      "{50: (0.5345209505978771, 'results/hBreast/BayesSpace/25/17/clusters/kmeans/50/3.00/umap/50/morans_i.jsonl')}\n",
      "{50: (0.5345209505978771, 'results/hBreast/BayesSpace/25/17/clusters/kmeans/50/3.00/umap/50/morans_i.jsonl'), 75: (0.5672553232229837, 'results/hBreast/BayesSpace/15/17/clusters/kmeans/75/3.00/umap/50/morans_i.jsonl')}\n",
      "{50: (0.5345209505978771, 'results/hBreast/BayesSpace/25/17/clusters/kmeans/50/3.00/umap/50/morans_i.jsonl'), 75: (0.5672553232229837, 'results/hBreast/BayesSpace/15/17/clusters/kmeans/75/3.00/umap/50/morans_i.jsonl'), 100: (0.5524041596747291, 'results/hBreast/BayesSpace/25/17/clusters/kmeans/100/3.00/umap/50/morans_i.jsonl')}\n",
      "{50: (0.30604937140564914, 'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i.jsonl')}\n",
      "{50: (0.30604937140564914, 'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i.jsonl'), 75: (0.41924982356972806, 'results/hBreast/Leiden/0.75/clusters/75/umap/50/morans_i.jsonl')}\n",
      "{50: (0.30604937140564914, 'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i.jsonl'), 75: (0.41924982356972806, 'results/hBreast/Leiden/0.75/clusters/75/umap/50/morans_i.jsonl'), 100: (0.42833561271094384, 'results/hBreast/Leiden/0.75/clusters/100/umap/50/morans_i.jsonl')}\n",
      "{50: (0.3105638025134567, 'results/hBreast/Louvain/1.0/clusters/50/umap/50/morans_i.jsonl')}\n",
      "{50: (0.3105638025134567, 'results/hBreast/Louvain/1.0/clusters/50/umap/50/morans_i.jsonl'), 75: (0.34635141616504117, 'results/hBreast/Louvain/1.0/clusters/75/umap/50/morans_i.jsonl')}\n",
      "{50: (0.3105638025134567, 'results/hBreast/Louvain/1.0/clusters/50/umap/50/morans_i.jsonl'), 75: (0.34635141616504117, 'results/hBreast/Louvain/1.0/clusters/75/umap/50/morans_i.jsonl'), 100: (0.4270866063595003, 'results/hBreast/Louvain/1.0/clusters/100/umap/50/morans_i.jsonl')}\n",
      "{50: (0.20553750757515749, 'results/hBreast/Hierarchical_No_Spatial/17/clusters/50/naive_distance/50/morans_i.jsonl')}\n",
      "{50: (0.20553750757515749, 'results/hBreast/Hierarchical_No_Spatial/17/clusters/50/naive_distance/50/morans_i.jsonl'), 75: (0.22124176956971578, 'results/hBreast/Hierarchical_No_Spatial/17/clusters/75/umap/50/morans_i.jsonl')}\n",
      "{50: (0.20553750757515749, 'results/hBreast/Hierarchical_No_Spatial/17/clusters/50/naive_distance/50/morans_i.jsonl'), 75: (0.22124176956971578, 'results/hBreast/Hierarchical_No_Spatial/17/clusters/75/umap/50/morans_i.jsonl'), 100: (0.2167002191378895, 'results/hBreast/Hierarchical_No_Spatial/17/clusters/100/umap/50/morans_i.jsonl')}\n",
      "{50: (0.24597487205847823, 'results/hBreast/K-Means/17/clusters/50/umap/50/morans_i.jsonl')}\n",
      "{50: (0.24597487205847823, 'results/hBreast/K-Means/17/clusters/50/umap/50/morans_i.jsonl'), 75: (0.26453030940118283, 'results/hBreast/K-Means/17/clusters/75/umap/50/morans_i.jsonl')}\n",
      "{50: (0.24597487205847823, 'results/hBreast/K-Means/17/clusters/50/umap/50/morans_i.jsonl'), 75: (0.26453030940118283, 'results/hBreast/K-Means/17/clusters/75/umap/50/morans_i.jsonl'), 100: (0.28076541763440827, 'results/hBreast/K-Means/17/clusters/100/umap/50/morans_i.jsonl')}\n",
      "{50: (0.3959039633724554, 'results/hBreast/mclust/15/17/clusters/50/umap/50/morans_i.jsonl')}\n",
      "{50: (0.3959039633724554, 'results/hBreast/mclust/15/17/clusters/50/umap/50/morans_i.jsonl'), 75: (0.4333516730934557, 'results/hBreast/mclust/25/17/clusters/75/umap/50/morans_i.jsonl')}\n",
      "{50: (0.3959039633724554, 'results/hBreast/mclust/15/17/clusters/50/umap/50/morans_i.jsonl'), 75: (0.4333516730934557, 'results/hBreast/mclust/25/17/clusters/75/umap/50/morans_i.jsonl'), 100: (0.4413824281924741, 'results/hBreast/mclust/25/17/clusters/100/umap/50/morans_i.jsonl')}\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where the results are stored\n",
    "results_dir = \"results/hBreast\"\n",
    "\n",
    "# Loop through all subdirectories in the results directory\n",
    "models = [\"BayXenSmooth\", \"BayesSpace\", \"Leiden\", \"Louvain\", \"Hierarchical_No_Spatial\", \"K-Means\", \"mclust\"]\n",
    "for model in models:\n",
    "    new_results_dir = os.path.join(results_dir, model)\n",
    "    morans_i_dict = {}\n",
    "    for spot_size in [50, 75, 100]:\n",
    "        current_best_MI = float('-inf')\n",
    "        current_best_filepath = \"\"\n",
    "        for root, dirs, files in os.walk(new_results_dir):\n",
    "            for file in files:\n",
    "                # Check if the file is named morans_i_by_gene.json\n",
    "                if file == \"morans_i.jsonl\":\n",
    "                    # Construct the full path to the file\n",
    "                    used_runs = [\"Leiden/0.75\", \"Louvain/1.0\"]\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    if not any(x in file_path for x in [\"Leiden\", \"Louvain\"]) or any(x in file_path for x in used_runs):\n",
    "                        # Open and read the file\n",
    "                        with open(file_path, 'r') as f:\n",
    "                            # Load the JSON data\n",
    "                            morans_i = [line for line in jsonlines.Reader(f)][0]\n",
    "                            # print(model, ((f\"{spot_size}\" in file_path.split('/')[:-2]) or (f\"SPOTSIZE={spot_size}\" in file_path.split('/')[:-2])))\n",
    "                            if morans_i > current_best_MI and ((f\"{spot_size}\" in file_path.split('/')[:-2]) or (f\"SPOTSIZE={spot_size}\" in file_path.split('/')[:-2])):\n",
    "                                current_best_MI = morans_i\n",
    "                                current_best_filepath = file_path\n",
    "\n",
    "        morans_i_dict[spot_size] = current_best_MI, current_best_filepath\n",
    "        print(morans_i_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50: (0.7367223964612759,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=Leiden/NEIGHBORSIZE=4/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=False/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/LOGITS_PRIOR=0.1/LEARN_GLOBAL_VARS=True/umap/50/morans_i.jsonl'),\n",
       " 75: (-inf,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=Leiden/NEIGHBORSIZE=4/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=False/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/LOGITS_PRIOR=0.1/LEARN_GLOBAL_VARS=True/umap/50/morans_i.jsonl'),\n",
       " 100: (-inf,\n",
       "  'results/hBreast/BayXenSmooth/clusters/PCA/25/INIT=Leiden/NEIGHBORSIZE=4/NUMCLUSTERS=17/SAMPLEFORASSIGNMENT=False/SPATIALPRIORMULT=DIRECT/SPOTSIZE=50/AGG=mean/MU_PRIOR=0.1/SIGMA_PRIOR=0.25/LOGITS_PRIOR=0.1/LEARN_GLOBAL_VARS=True/umap/50/morans_i.jsonl')}"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morans_i_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Moran's I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "MARKER_GENES = [\"BANK1\", \"CEACAM6\", \"FASN\", \"FGL2\", \"IL7R\", \"KRT6B\", \"POSTN\", \"TCIM\"]\n",
    "\n",
    "# Define the directory where the results are stored\n",
    "results_dir = \"results/hBreast\"\n",
    "\n",
    "# Loop through all subdirectories in the results directory\n",
    "morans_i_dict = {}\n",
    "for gene_name in MARKER_GENES:\n",
    "    current_max_expression = 0\n",
    "    current_best_mpd = float('inf')\n",
    "    for root, dirs, files in os.walk(results_dir):\n",
    "        for file in files:\n",
    "            # Check if the file is named morans_i_by_gene.json\n",
    "            if file == \"morans_i_by_gene.jsonl\":\n",
    "                # Construct the full path to the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Open and read the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    # Load the JSON data\n",
    "                    data = [line for line in jsonlines.Reader(f)]\n",
    "                    # Print the data to verify it's been loaded\n",
    "                    morans_i = [x for x in data if gene_name in x]\n",
    "                    unused_runs = [\"Leiden/2.0\", \"Leiden/1.5\", \"Louvain/2.0\", \"Louvain/1.5\"]\n",
    "                    if morans_i[0][gene_name] > current_max_expression and \"50/\" in file_path and not any(x in file_path for x in unused_runs):\n",
    "                        current_max_filepath = file_path\n",
    "                        current_max_expression = morans_i[0][gene_name]\n",
    "                        mpd_root = root\n",
    "                        pattern = r\"(?:umap|naive_distance|gauss|basic)/\\d+\"\n",
    "                        mpd_root = re.sub(pattern, \"\", mpd_root)\n",
    "                        mpd_dir = mpd_root.replace(\"clusters\", \"mpd\")\n",
    "                        mpd_file = next((f for f in os.listdir(mpd_dir) if f.endswith(\".json\")), None)\n",
    "                        if mpd_file:\n",
    "                            with open(os.path.join(mpd_dir, mpd_file)) as f:\n",
    "                                mpd_dict = json.load(f)\n",
    "                                if len(mpd_dict) == K:\n",
    "                                    current_best_mpd = sum(mpd_dict.values()) / 1_000_000\n",
    "                                else:\n",
    "                                    current_best_mpd = (sum(mpd_dict.values()) / 1_000_000, f\"(but K* = {len(mpd_dict)})\")\n",
    "    morans_i_dict[gene_name] = current_max_expression, current_max_filepath, current_best_mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morans_i_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Methods Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the directory where the results are stored\n",
    "# results_dirs = [\"results/hBreast/BayXenSmooth\", \"results/hBreast/BayesSpace\"]\n",
    "results_dirs = [\"results/hBreast/Leiden\"]\n",
    "\n",
    "# Loop through all subdirectories in the results directory\n",
    "morans_i_dict = {}\n",
    "for gene_name in MARKER_GENES:\n",
    "    current_max_expression = 0\n",
    "    current_best_mpd = float('inf')\n",
    "    for dir in results_dirs:\n",
    "        for root, dirs, files in os.walk(dir):\n",
    "            for file in files:\n",
    "                # Check if the file is named morans_i_by_gene.json\n",
    "                if file == \"morans_i_by_gene.jsonl\":\n",
    "                    # Construct the full path to the file\n",
    "                    file_path = os.path.join(root, file)\n",
    "\n",
    "                    # Open and read the file\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        # Load the JSON data\n",
    "                        data = [line for line in jsonlines.Reader(f)]\n",
    "                        # Print the data to verify it's been loaded\n",
    "                        morans_i = [x for x in data if gene_name in x]\n",
    "                        used_runs = [\"Leiden/0.75\", \"Louvain/1.0\"]\n",
    "                        if morans_i[0][gene_name] > current_max_expression and \"50/\" in file_path:\n",
    "                            if not any(x in file_path for x in [\"Leiden\", \"Louvain\"]) or any(x in file_path for x in used_runs):\n",
    "                                current_max_filepath = file_path\n",
    "                                current_max_expression = morans_i[0][gene_name]\n",
    "                                mpd_root = root\n",
    "                                pattern = r\"(?:umap|naive_distance|gauss|basic)/\\d+\"\n",
    "                                mpd_root = re.sub(pattern, \"\", mpd_root)\n",
    "                                mpd_dir = mpd_root.replace(\"clusters\", \"mpd\")\n",
    "                                mpd_file = next((f for f in os.listdir(mpd_dir) if f.endswith(\".json\")), None)\n",
    "                                if mpd_file:\n",
    "                                    with open(os.path.join(mpd_dir, mpd_file)) as f:\n",
    "                                        mpd_dict = json.load(f)\n",
    "                                        if len(mpd_dict) == K:\n",
    "                                            current_best_mpd = sum(mpd_dict.values()) / 1_000\n",
    "                                        else:\n",
    "                                            current_best_mpd = (sum(mpd_dict.values()) / 1_000, f\"(but K* = {len(mpd_dict)})\")\n",
    "        morans_i_dict[gene_name] = current_max_expression, current_max_filepath, current_best_mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BANK1': (1.4739417834190855,\n",
       "  'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i_by_gene.jsonl',\n",
       "  55.93160193262027),\n",
       " 'CEACAM6': (0.34395234742791236,\n",
       "  'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i_by_gene.jsonl',\n",
       "  55.93160193262027),\n",
       " 'FASN': (0.9982649300206032,\n",
       "  'results/hBreast/Leiden/0.75/clusters/50/umap/400/morans_i_by_gene.jsonl',\n",
       "  55.93160193262027),\n",
       " 'FGL2': (0.5810988489304812,\n",
       "  'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i_by_gene.jsonl',\n",
       "  55.93160193262027),\n",
       " 'IL7R': (1.0562251422009445,\n",
       "  'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i_by_gene.jsonl',\n",
       "  55.93160193262027),\n",
       " 'KRT6B': (0.9815267718202886,\n",
       "  'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i_by_gene.jsonl',\n",
       "  55.93160193262027),\n",
       " 'POSTN': (0.6224454538593952,\n",
       "  'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i_by_gene.jsonl',\n",
       "  55.93160193262027),\n",
       " 'TCIM': (0.8467029807415433,\n",
       "  'results/hBreast/Leiden/0.75/clusters/50/umap/50/morans_i_by_gene.jsonl',\n",
       "  55.93160193262027)}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morans_i_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows.shape, bank1_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Get the index of the gene \n",
    "\n",
    "gene = \"BANK1\"\n",
    "\n",
    "bank1_index = clustering.xenium_spot_data.var.index.get_loc(gene)\n",
    "\n",
    "# Extract the data for \"BANK1\"\n",
    "bank1_data = torch.tensor(clustering.xenium_spot_data.X[:, bank1_index])\n",
    "\n",
    "rows = clustering.xenium_spot_data.obs[\"row\"].astype(int)\n",
    "columns = clustering.xenium_spot_data.obs[\"col\"].astype(int)\n",
    "\n",
    "num_rows = max(rows) + 1\n",
    "num_cols = max(columns) + 1\n",
    "\n",
    "marker_grid = torch.zeros(num_rows, num_cols, dtype=float)\n",
    "\n",
    "marker_grid[rows, columns] = bank1_data\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(marker_grid, origin='lower')  # Invert the y-axis by setting origin to 'upper'\n",
    "plt.title(f'Expression of {gene}')\n",
    "plt.xlabel('Row')\n",
    "plt.ylabel('Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(clustering.xenium_spot_data.var[\"BANK1\"], cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_per_side = 100\n",
    "\n",
    "print(\"Starting Moran's I Calculation.\")\n",
    "moran_clusters = ad.AnnData(locations)\n",
    "sc.pp.neighbors(moran_clusters, n_pcs=0, n_neighbors=100)\n",
    "print(\"Neighbors calculated.\")\n",
    "\n",
    "connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "# connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()\n",
    "\n",
    "# Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "cluster_labels = clusters.values\n",
    "same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "print(moran_clusters.obsp[\"connectivities\"].shape, same_cluster.shape)\n",
    "moran_clusters.obsp[\"connectivities\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "print(\"Connectivities formed.\")\n",
    "\n",
    "# Calculate Moran's I for the genes\n",
    "morans_i = sc.metrics.morans_i(moran_clusters, vals=clustering.xenium_spot_data.X.T)\n",
    "\n",
    "morans_i_dict = dict(zip(clustering.xenium_spot_data.var.index, morans_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_per_side = 100\n",
    "\n",
    "print(\"Starting Moran's I Calculation.\")\n",
    "moran_clusters = ad.AnnData(locations)\n",
    "sc.pp.neighbors(moran_clusters, n_pcs=0, n_neighbors=100)\n",
    "print(\"Neighbors calculated.\")\n",
    "\n",
    "connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "# connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()\n",
    "\n",
    "# Create a binary adjacency matrix indicating if points are in the same cluster\n",
    "cluster_labels = clusters.values\n",
    "same_cluster = (cluster_labels[:, None] == cluster_labels).astype(int)\n",
    "print(moran_clusters.obsp[\"connectivities\"].shape, same_cluster.shape)\n",
    "moran_clusters.obsp[\"connectivities\"] = moran_clusters.obsp[\"connectivities\"].multiply(csr_matrix(same_cluster))\n",
    "print(\"Connectivities formed.\")\n",
    "\n",
    "# Calculate Moran's I for the genes\n",
    "morans_i = sc.metrics.morans_i(moran_clusters, vals=clustering.xenium_spot_data.X.T)\n",
    "\n",
    "morans_i_dict = dict(zip(clustering.xenium_spot_data.var.index, morans_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first 10x10 submatrix of the connectivities matrix\n",
    "connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "# connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spots_per_side = 100\n",
    "\n",
    "# Extract the first 10x10 submatrix of the connectivities matrix\n",
    "# connectivities_submatrix = moran_clusters.obsp[\"connectivities\"][:spots_per_side, :spots_per_side].A\n",
    "connectivities_submatrix = same_cluster[:spots_per_side, :spots_per_side]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(connectivities_submatrix, cmap='Blues')\n",
    "plt.title('Connectivities Heatmap')\n",
    "plt.xlabel('Spot Index')\n",
    "plt.ylabel('Spot Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check of Clusters and Moran's I Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "num_clusters = K\n",
    "\n",
    "rows = locations[\"row\"].astype(int)\n",
    "columns = locations[\"col\"].astype(int)\n",
    "\n",
    "num_rows = max(rows) + 1\n",
    "num_cols = max(columns) + 1\n",
    "\n",
    "cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.long)\n",
    "\n",
    "cluster_grid[rows, columns] = torch.tensor(clusters) + 1\n",
    "\n",
    "colors = plt.cm.get_cmap('viridis', num_clusters + 1)\n",
    "\n",
    "colormap_colors = np.vstack(([[1, 1, 1, 1]], colors(np.linspace(0, 1, num_clusters))))\n",
    "colormap = ListedColormap(colormap_colors)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cluster_grid, cmap=colormap, interpolation='nearest', origin='lower')\n",
    "plt.colorbar(ticks=range(num_clusters + 1), label='Cluster Values')\n",
    "plt.title('Prior Cluster Assignment with BayXenSmooth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory to search\n",
    "search_directory = 'results/hBreast/BayesSpace'\n",
    "\n",
    "# List to store the paths of all .csv files\n",
    "csv_files = []\n",
    "\n",
    "# Walk through the directory\n",
    "for root, dirs, files in os.walk(search_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            clusters = pd.read_csv(os.path.join(root, file))[\"BayesSpace cluster\"]\n",
    "            print(os.path.join(root, file), len(np.unique(clusters.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
