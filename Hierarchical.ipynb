{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from importlib import reload\n",
    "\n",
    "# this ensures that I can update the class without losing my variables in my notebook\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .gz file\n",
    "file_path = 'data/hBreast/transcripts.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file into a DataFrame\n",
    "df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# drop cells without ids\n",
    "df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "# drop blanks and controls\n",
    "df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data, dataset_name: str, current_spot_size: int, third_dim: bool, resolutions: list, n_clusters=15):\n",
    "    \n",
    "    clustering = XeniumCluster(data=data, dataset_name=dataset_name)\n",
    "    clustering.set_spot_size(current_spot_size)\n",
    "    clustering.create_spot_data(third_dim=third_dim, save_data=True)\n",
    "\n",
    "    print(f\"The size of the spot data is {clustering.xenium_spot_data.shape}\")\n",
    "\n",
    "    clustering.normalize_counts(clustering.xenium_spot_data)\n",
    "    clustering.generate_neighborhood_graph(clustering.xenium_spot_data, plot_pcas=False)\n",
    "\n",
    "    hierarchical_cluster = clustering.Hierarchical(clustering.xenium_spot_data, embedding=\"umap\", save_plot=True, num_clusters=n_clusters, include_spatial=True)\n",
    "    hierarchical_cluster_no_spatial = clustering.Hierarchical(clustering.xenium_spot_data, embedding=\"umap\", save_plot=True, num_clusters=n_clusters, include_spatial=False)\n",
    "    return clustering, hierarchical_cluster, hierarchical_cluster_no_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def record_results(original_data, cluster_dict, results_dir, model_name, filename, spot_size, third_dim, K=None, resolution=None, uses_spatial=True):\n",
    "\n",
    "    dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/clusters/{spot_size}\"\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    filepath = f\"{dirpath}/{filename}.json\"\n",
    "\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(cluster_dict[model_name], f, indent=4)\n",
    "\n",
    "    wss = {}\n",
    "    if resolution is not None:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim].get(\n",
    "            resolution, \n",
    "            cluster_dict[model_name][spot_size][third_dim]\n",
    "        ))\n",
    "    else:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim][uses_spatial].get(\n",
    "            K, \n",
    "            cluster_dict[model_name][spot_size][third_dim][uses_spatial]\n",
    "        ))\n",
    "    cluster_labels = np.unique(current_clustering)\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"] = np.array(current_clustering)\n",
    "    # Extracting row, col, and cluster values from the dataframe\n",
    "    rows = torch.tensor(original_data.xenium_spot_data.obs[\"row\"].astype(int))\n",
    "    cols = torch.tensor(original_data.xenium_spot_data.obs[\"col\"].astype(int))\n",
    "    clusters = torch.tensor(original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].astype(int))\n",
    "    cluster_labels = np.unique(clusters)\n",
    "\n",
    "    num_rows = int(max(rows) - min(rows) + 1)\n",
    "    num_cols = int(max(cols) - min(cols) + 1)\n",
    "\n",
    "    cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.int)\n",
    "\n",
    "    cluster_grid[rows, cols] = torch.tensor(clusters, dtype=torch.int)\n",
    "\n",
    "    for label in cluster_labels:\n",
    "        current_cluster_locations = torch.stack(torch.where((cluster_grid == label)), axis=1).to(float)\n",
    "        wss[f\"Cluster {label}\"] = (spot_size ** 2) * torch.mean(torch.cdist(current_cluster_locations, current_cluster_locations)).item()\n",
    "        print(f\"POSSIBLE {len(cluster_labels)}\", label, wss[f\"Cluster {label}\"])\n",
    "\n",
    "    wss_dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/wss/{spot_size}/\"\n",
    "    if not os.path.exists(wss_dirpath):\n",
    "        os.makedirs(wss_dirpath)\n",
    "\n",
    "    wss_filepath = f\"{wss_dirpath}/{filename}_wss.json\"\n",
    "    with open(wss_filepath, \"w\") as f:\n",
    "        json.dump(wss, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {\"Hierarchical\": {}}\n",
    "wss = {\"Hierarchical\": {}}\n",
    "results_dir = \"results/hBreast\"\n",
    "cluster_results_filename = \"clusters_w_plots_7_26\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the spot data is (23444, 280)\n",
      "POSSIBLE 17 0 1180039.504558521\n",
      "POSSIBLE 17 1 775883.8204336059\n",
      "POSSIBLE 17 2 615031.8135502671\n",
      "POSSIBLE 17 3 749199.9148159687\n",
      "POSSIBLE 17 4 670498.214283633\n",
      "POSSIBLE 17 5 544792.2395362895\n",
      "POSSIBLE 17 6 707324.4806051941\n",
      "POSSIBLE 17 7 561303.1343901939\n",
      "POSSIBLE 17 8 642662.5441927266\n",
      "POSSIBLE 17 9 620485.2155417284\n",
      "POSSIBLE 17 10 807473.0247055839\n",
      "POSSIBLE 17 11 776391.5687309722\n",
      "POSSIBLE 17 12 778661.3027766403\n",
      "POSSIBLE 17 13 609647.170081577\n",
      "POSSIBLE 17 14 826355.6013837887\n",
      "POSSIBLE 17 15 768462.0504403978\n",
      "POSSIBLE 17 16 690189.6603324814\n",
      "POSSIBLE 17 0 1168476.0205119394\n",
      "POSSIBLE 17 1 838879.5533621671\n",
      "POSSIBLE 17 2 781241.7950899021\n",
      "POSSIBLE 17 3 777569.9499023024\n",
      "POSSIBLE 17 4 632532.2027262276\n",
      "POSSIBLE 17 5 504952.6039926683\n",
      "POSSIBLE 17 6 593863.8673920567\n",
      "POSSIBLE 17 7 696763.6153476669\n",
      "POSSIBLE 17 8 708156.2928911858\n",
      "POSSIBLE 17 9 757159.0411464348\n",
      "POSSIBLE 17 10 693192.2485888735\n",
      "POSSIBLE 17 11 626238.6867582104\n",
      "POSSIBLE 17 12 809212.6695946599\n",
      "POSSIBLE 17 13 708084.8410792804\n",
      "POSSIBLE 17 14 764899.362678848\n",
      "POSSIBLE 17 15 621684.2433684391\n",
      "POSSIBLE 17 16 685074.3941728099\n",
      "Cluster with spot size (50, False, 17) completed.\n",
      "The size of the spot data is (10734, 280)\n",
      "POSSIBLE 17 0 773377.4135321943\n",
      "POSSIBLE 17 1 512837.1270197982\n",
      "POSSIBLE 17 2 457148.92310297815\n",
      "POSSIBLE 17 3 413547.5842078158\n",
      "POSSIBLE 17 4 504283.1951329546\n",
      "POSSIBLE 17 5 520029.6677210722\n",
      "POSSIBLE 17 6 404663.39617072494\n",
      "POSSIBLE 17 7 354939.5113524146\n",
      "POSSIBLE 17 8 334405.08101877413\n",
      "POSSIBLE 17 9 452018.79161760095\n",
      "POSSIBLE 17 10 517526.9602490187\n",
      "POSSIBLE 17 11 502357.551187708\n",
      "POSSIBLE 17 12 486115.8536661983\n",
      "POSSIBLE 17 13 414890.5859319476\n",
      "POSSIBLE 17 14 404764.09930524096\n",
      "POSSIBLE 17 15 385413.1553445458\n",
      "POSSIBLE 17 16 502198.0696382894\n",
      "POSSIBLE 17 0 791300.0944758984\n",
      "POSSIBLE 17 1 450419.42832308635\n",
      "POSSIBLE 17 2 533479.4227556442\n",
      "POSSIBLE 17 3 507746.61857074726\n",
      "POSSIBLE 17 4 403915.02355641045\n",
      "POSSIBLE 17 5 495225.6122391341\n",
      "POSSIBLE 17 6 401705.5801250571\n",
      "POSSIBLE 17 7 519969.19951768033\n",
      "POSSIBLE 17 8 419622.32911109686\n",
      "POSSIBLE 17 9 337981.26448503474\n",
      "POSSIBLE 17 10 437693.4186566032\n",
      "POSSIBLE 17 11 528944.154517525\n",
      "POSSIBLE 17 12 356230.11736041255\n",
      "POSSIBLE 17 13 412408.8028514488\n",
      "POSSIBLE 17 14 508381.87029651616\n",
      "POSSIBLE 17 15 490772.46589609643\n",
      "POSSIBLE 17 16 431654.5098211571\n",
      "Cluster with spot size (75, False, 17) completed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m third_dim \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mFalse\u001b[39;00m]:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m K \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m17\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m         original_data, k_means_cluster, k_means_cluster_no_spatial \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_transcripts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhBreast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspot_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthird_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolutions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# Hierarchical Spatial\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHierarchical\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cluster_dict:\n",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(data, dataset_name, current_spot_size, third_dim, resolutions, n_clusters)\u001b[0m\n\u001b[1;32m      3\u001b[0m clustering \u001b[38;5;241m=\u001b[39m XeniumCluster(data\u001b[38;5;241m=\u001b[39mdata, dataset_name\u001b[38;5;241m=\u001b[39mdataset_name)\n\u001b[1;32m      4\u001b[0m clustering\u001b[38;5;241m.\u001b[39mset_spot_size(current_spot_size)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mclustering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_spot_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthird_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthird_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe size of the spot data is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclustering\u001b[38;5;241m.\u001b[39mxenium_spot_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m clustering\u001b[38;5;241m.\u001b[39mnormalize_counts(clustering\u001b[38;5;241m.\u001b[39mxenium_spot_data)\n",
      "File \u001b[0;32m~/xenium/xenium_cluster.py:62\u001b[0m, in \u001b[0;36mXeniumCluster.create_spot_data\u001b[0;34m(self, third_dim, save_data)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_spot_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, third_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, save_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 62\u001b[0m     x_min, x_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_xenium_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_location\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_xenium_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_location\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     63\u001b[0m     y_min, y_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_xenium_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_location\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_xenium_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_location\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     65\u001b[0m     MIN_PAD \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-8\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "resolutions = [0.1, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0]\n",
    "for spot_size in [50, 75, 100]:\n",
    "    for third_dim in [False]:\n",
    "        for K in [17]:\n",
    "            original_data, hierarchical_cluster, hierarchical_cluster_no_spatial = run_experiment(df_transcripts, \"hBreast\", spot_size, third_dim, resolutions, n_clusters=K)\n",
    "            # Hierarchical Spatial\n",
    "            if \"Hierarchical\" not in cluster_dict:\n",
    "                cluster_dict[\"Hierarchical\"] = {}\n",
    "            if spot_size not in cluster_dict[\"Hierarchical\"]:\n",
    "                cluster_dict[\"Hierarchical\"][spot_size] = {}\n",
    "            cluster_dict[\"Hierarchical\"][spot_size][third_dim] = {True: {K: hierarchical_cluster.tolist()}}\n",
    "            record_results(original_data, cluster_dict, results_dir, \"Hierarchical\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=True)\n",
    "\n",
    "            # Hierarchical No Spatial\n",
    "            if \"Hierarchical_No_Spatial\" not in cluster_dict:\n",
    "                cluster_dict[\"Hierarchical_No_Spatial\"] = {}\n",
    "            if spot_size not in cluster_dict[\"Hierarchical_No_Spatial\"]:\n",
    "                cluster_dict[\"Hierarchical_No_Spatial\"][spot_size] = {}\n",
    "            cluster_dict[\"Hierarchical_No_Spatial\"][spot_size][third_dim] = {False: {K: hierarchical_cluster_no_spatial.tolist()}}\n",
    "            record_results(original_data, cluster_dict, results_dir, \"Hierarchical_No_Spatial\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=False)\n",
    "\n",
    "            print(f\"Cluster with spot size {(spot_size, third_dim, K)} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "Method: K-Means Spot Size 100 Num Clusters: 17 Total WSS 0.005813899414138968\n",
      "HERE\n",
      "Method: K-Means_No_Spatial Spot Size 100 Num Clusters: 17 Total WSS 0.28332006679553495\n",
      "HERE\n",
      "Method: Hierarchical Spot Size 100 Num Clusters: 17 Total WSS 0.00560841868163628\n",
      "HERE\n",
      "Method: Hierarchical_No_Spatial Spot Size 100 Num Clusters: 17 Total WSS 0.28219239547169006\n",
      "Method: Leiden Spot Size 100 Resolution 0.25 Num Clusters: 6 Total WSS 0.09779246825275083\n",
      "Method: Leiden Spot Size 100 Resolution 0.5 Num Clusters: 9 Total WSS 0.12700534134305\n",
      "Method: Leiden Spot Size 100 Resolution 0.75 Num Clusters: 14 Total WSS 0.2060176697480106\n",
      "Method: Leiden Spot Size 100 Resolution 1.0 Num Clusters: 17 Total WSS 0.2464717861724789\n",
      "Method: Louvain Spot Size 100 Resolution 0.25 Num Clusters: 4 Total WSS 0.0661864015541885\n",
      "Method: Louvain Spot Size 100 Resolution 0.5 Num Clusters: 8 Total WSS 0.12385353960127954\n",
      "Method: Louvain Spot Size 100 Resolution 0.75 Num Clusters: 10 Total WSS 0.15173654314022136\n",
      "Method: Louvain Spot Size 100 Resolution 1.0 Num Clusters: 14 Total WSS 0.1888743130990558\n"
     ]
    }
   ],
   "source": [
    "spot_sizes = [50,75,100]\n",
    "resolutions = [0.25, 0.5, 0.75, 1.0]\n",
    "methods = [\"Hierarchical\", \"Hierarchical_No_Spatial\"]\n",
    "in_billions = 1_000_000_000\n",
    "for method in methods:\n",
    "    for spot_size in spot_sizes:\n",
    "        for K in [17]:\n",
    "            filename = f\"results/hBreast/{method}/{K}/wss/{spot_size}/{cluster_results_filename}_wss.json\"\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, \"r\") as wss_dict:\n",
    "                    current_wss = json.load(wss_dict)\n",
    "                print(\"Method:\", method, \"Spot Size\", spot_size, \"Num Clusters:\", len(current_wss), \"Total WSS\", sum(current_wss.values()) / in_billions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
