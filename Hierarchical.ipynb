{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from importlib import reload\n",
    "\n",
    "# this ensures that I can update the class without losing my variables in my notebook\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .gz file\n",
    "file_path = 'data/hBreast/transcripts.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file into a DataFrame\n",
    "df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# drop cells without ids\n",
    "df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "# drop blanks and controls\n",
    "df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data, dataset_name: str, current_spot_size: int, third_dim: bool, n_clusters=15):\n",
    "    \n",
    "    clustering = XeniumCluster(data=data, dataset_name=dataset_name)\n",
    "    clustering.set_spot_size(current_spot_size)\n",
    "    clustering.create_spot_data(third_dim=third_dim, save_data=True)\n",
    "\n",
    "    print(f\"The size of the spot data is {clustering.xenium_spot_data.shape}\")\n",
    "\n",
    "    clustering.normalize_counts(clustering.xenium_spot_data)\n",
    "    clustering.generate_neighborhood_graph(clustering.xenium_spot_data, plot_pcas=False)\n",
    "\n",
    "    hierarchical_cluster = clustering.Hierarchical(clustering.xenium_spot_data, embedding=\"umap\", save_plot=True, num_clusters=n_clusters, include_spatial=True)\n",
    "    hierarchical_cluster_no_spatial = clustering.Hierarchical(clustering.xenium_spot_data, embedding=\"umap\", save_plot=True, num_clusters=n_clusters, include_spatial=False)\n",
    "    return clustering, hierarchical_cluster, hierarchical_cluster_no_spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def record_results(original_data, cluster_dict, results_dir, model_name, filename, spot_size, third_dim, K=None, resolution=None, uses_spatial=True):\n",
    "\n",
    "    if resolution is not None:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim].get(\n",
    "            resolution, \n",
    "            cluster_dict[model_name][spot_size][third_dim]\n",
    "        ))\n",
    "    else:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim][uses_spatial].get(\n",
    "            K, \n",
    "            cluster_dict[model_name][spot_size][third_dim][uses_spatial]\n",
    "        ))\n",
    "    cluster_labels = np.unique(current_clustering)\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"] = np.array(current_clustering)\n",
    "    dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/clusters/{spot_size}\"\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    filepath = f\"{dirpath}/{filename}.csv\"\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].to_csv(filepath)\n",
    "    # Extracting row, col, and cluster values from the dataframe\n",
    "    rows = torch.tensor(original_data.xenium_spot_data.obs[\"row\"].astype(int))\n",
    "    cols = torch.tensor(original_data.xenium_spot_data.obs[\"col\"].astype(int))\n",
    "    clusters = torch.tensor(original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].astype(int))\n",
    "    cluster_labels = np.unique(clusters)\n",
    "\n",
    "    num_rows = int(max(rows) - min(rows) + 1)\n",
    "    num_cols = int(max(cols) - min(cols) + 1)\n",
    "\n",
    "    cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.int)\n",
    "\n",
    "    cluster_grid[rows, cols] = torch.tensor(clusters, dtype=torch.int)\n",
    "\n",
    "    mpd = {}\n",
    "    for label in cluster_labels:\n",
    "        current_cluster_locations = torch.stack(torch.where((cluster_grid == label)), axis=1).to(float)\n",
    "        mpd[f\"Cluster {label}\"] = spot_size * torch.mean(torch.cdist(current_cluster_locations, current_cluster_locations)).item()\n",
    "        print(f\"POSSIBLE {len(cluster_labels)}\", label, mpd[f\"Cluster {label}\"])\n",
    "\n",
    "    mpd_dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/mpd/{spot_size}/\"\n",
    "    if not os.path.exists(mpd_dirpath):\n",
    "        os.makedirs(mpd_dirpath)\n",
    "\n",
    "    mpd_filepath = f\"{mpd_dirpath}/{filename}_mpd.json\"\n",
    "    with open(mpd_filepath, \"w\") as f:\n",
    "        json.dump(mpd, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {\"Hierarchical\": {}}\n",
    "mpd = {\"Hierarchical\": {}}\n",
    "results_dir = \"results/hBreast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the spot data is (23444, 280)\n",
      "WARNING: You’re trying to run this on 282 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n",
      "POSSIBLE 17 1 153864.3839623562\n",
      "POSSIBLE 17 2 181139.9579898963\n",
      "POSSIBLE 17 3 174051.86829250678\n",
      "POSSIBLE 17 4 176394.63673151995\n",
      "POSSIBLE 17 5 200088.21236640622\n",
      "POSSIBLE 17 6 101419.24866749704\n",
      "POSSIBLE 17 7 173969.50045129895\n",
      "POSSIBLE 17 8 190205.5668843859\n",
      "POSSIBLE 17 9 187693.10388498253\n",
      "POSSIBLE 17 10 199404.7335029722\n",
      "POSSIBLE 17 11 206176.03182383964\n",
      "POSSIBLE 17 12 182243.58620968836\n",
      "POSSIBLE 17 13 201306.95050688254\n",
      "POSSIBLE 17 14 211848.84017789725\n",
      "POSSIBLE 17 15 167620.2847518643\n",
      "POSSIBLE 17 16 172352.65105919773\n",
      "POSSIBLE 17 17 173337.4241952826\n",
      "POSSIBLE 17 1 201950.5191518618\n",
      "POSSIBLE 17 2 162090.42835014788\n",
      "POSSIBLE 17 3 178974.10069722714\n",
      "POSSIBLE 17 4 157685.24716399235\n",
      "POSSIBLE 17 5 149022.7198240636\n",
      "POSSIBLE 17 6 176453.61099130713\n",
      "POSSIBLE 17 7 166999.77822537054\n",
      "POSSIBLE 17 8 147984.1857074606\n",
      "POSSIBLE 17 9 169490.59700276295\n",
      "POSSIBLE 17 10 183306.93841412483\n",
      "POSSIBLE 17 11 209788.1206549276\n",
      "POSSIBLE 17 12 172067.46152065325\n",
      "POSSIBLE 17 13 214009.63822281567\n",
      "POSSIBLE 17 14 201762.40590795313\n",
      "POSSIBLE 17 15 152659.67415088767\n",
      "POSSIBLE 17 16 145209.6306700292\n",
      "POSSIBLE 17 17 176473.17468813938\n",
      "Cluster with spot size (50, False, 17) completed.\n",
      "The size of the spot data is (10734, 280)\n",
      "WARNING: You’re trying to run this on 282 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n",
      "POSSIBLE 17 1 276863.6886616986\n",
      "POSSIBLE 17 2 256450.93407202617\n",
      "POSSIBLE 17 3 261676.73891819338\n",
      "POSSIBLE 17 4 234961.95237233143\n",
      "POSSIBLE 17 5 237375.47107810178\n",
      "POSSIBLE 17 6 138506.51312264102\n",
      "POSSIBLE 17 7 322510.4172122669\n",
      "POSSIBLE 17 8 315638.7278425305\n",
      "POSSIBLE 17 9 289817.1927502575\n",
      "POSSIBLE 17 10 311070.9741636325\n",
      "POSSIBLE 17 11 288376.89497340564\n",
      "POSSIBLE 17 12 223330.68368596266\n",
      "POSSIBLE 17 13 262228.63874930615\n",
      "POSSIBLE 17 14 240467.0505855635\n",
      "POSSIBLE 17 15 275643.4143941831\n",
      "POSSIBLE 17 16 290107.8563706267\n",
      "POSSIBLE 17 17 256674.91270393113\n",
      "POSSIBLE 17 1 257882.62390863156\n",
      "POSSIBLE 17 2 253584.45613296388\n",
      "POSSIBLE 17 3 253110.88423170004\n",
      "POSSIBLE 17 4 204251.90372691661\n",
      "POSSIBLE 17 5 248456.92491836593\n",
      "POSSIBLE 17 6 169143.68745619632\n",
      "POSSIBLE 17 7 298013.11719874776\n",
      "POSSIBLE 17 8 229895.89704237672\n",
      "POSSIBLE 17 9 249163.16580249256\n",
      "POSSIBLE 17 10 347250.4061517763\n",
      "POSSIBLE 17 11 310207.3296587512\n",
      "POSSIBLE 17 12 226863.54118717957\n",
      "POSSIBLE 17 13 249061.86174389467\n",
      "POSSIBLE 17 14 251576.08141846853\n",
      "POSSIBLE 17 15 302165.8955220825\n",
      "POSSIBLE 17 16 271151.0656225914\n",
      "POSSIBLE 17 17 255655.16713715746\n",
      "Cluster with spot size (75, False, 17) completed.\n",
      "The size of the spot data is (6138, 280)\n",
      "WARNING: You’re trying to run this on 282 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n",
      "POSSIBLE 17 1 343461.2002970781\n",
      "POSSIBLE 17 2 348500.3593928649\n",
      "POSSIBLE 17 3 292292.6369118401\n",
      "POSSIBLE 17 4 324101.6698754096\n",
      "POSSIBLE 17 5 366673.0534584655\n",
      "POSSIBLE 17 6 326705.34236506844\n",
      "POSSIBLE 17 7 367520.75267189054\n",
      "POSSIBLE 17 8 359850.1275164964\n",
      "POSSIBLE 17 9 322278.4845570015\n",
      "POSSIBLE 17 10 347561.31012567546\n",
      "POSSIBLE 17 11 322191.6254809705\n",
      "POSSIBLE 17 12 467077.12539072474\n",
      "POSSIBLE 17 13 424184.05297623907\n",
      "POSSIBLE 17 14 409225.83184398455\n",
      "POSSIBLE 17 15 224780.2767221039\n",
      "POSSIBLE 17 16 73463.2965119674\n",
      "POSSIBLE 17 17 288551.53553849907\n",
      "POSSIBLE 17 1 297094.0711914169\n",
      "POSSIBLE 17 2 346789.7837604813\n",
      "POSSIBLE 17 3 312222.22946185025\n",
      "POSSIBLE 17 4 190304.19555037876\n",
      "POSSIBLE 17 5 284934.4608314038\n",
      "POSSIBLE 17 6 356812.1087599728\n",
      "POSSIBLE 17 7 380938.94921664865\n",
      "POSSIBLE 17 8 359906.0618390862\n",
      "POSSIBLE 17 9 305861.66890328674\n",
      "POSSIBLE 17 10 318456.80703061115\n",
      "POSSIBLE 17 11 451855.3373584063\n",
      "POSSIBLE 17 12 371645.15389295976\n",
      "POSSIBLE 17 13 349124.33568836306\n",
      "POSSIBLE 17 14 322134.39894304174\n",
      "POSSIBLE 17 15 329008.5514164163\n",
      "POSSIBLE 17 16 426509.9372624742\n",
      "POSSIBLE 17 17 392429.6763793342\n",
      "Cluster with spot size (100, False, 17) completed.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "for spot_size in [50, 75, 100]:\n",
    "    for third_dim in [False]:\n",
    "        for K in [17]:\n",
    "            cluster_results_filename = f\"clusters_K={K}\"\n",
    "            original_data, hierarchical_cluster, hierarchical_cluster_no_spatial = run_experiment(df_transcripts, \"hBreast\", spot_size, third_dim, n_clusters=K)\n",
    "            # Hierarchical Spatial\n",
    "            if \"Hierarchical\" not in cluster_dict:\n",
    "                cluster_dict[\"Hierarchical\"] = {}\n",
    "            if spot_size not in cluster_dict[\"Hierarchical\"]:\n",
    "                cluster_dict[\"Hierarchical\"][spot_size] = {}\n",
    "            cluster_dict[\"Hierarchical\"][spot_size][third_dim] = {True: {K: hierarchical_cluster.tolist()}}\n",
    "            record_results(original_data, cluster_dict, results_dir, \"Hierarchical\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=True)\n",
    "\n",
    "            # Hierarchical No Spatial\n",
    "            if \"Hierarchical_No_Spatial\" not in cluster_dict:\n",
    "                cluster_dict[\"Hierarchical_No_Spatial\"] = {}\n",
    "            if spot_size not in cluster_dict[\"Hierarchical_No_Spatial\"]:\n",
    "                cluster_dict[\"Hierarchical_No_Spatial\"][spot_size] = {}\n",
    "            cluster_dict[\"Hierarchical_No_Spatial\"][spot_size][third_dim] = {False: {K: hierarchical_cluster_no_spatial.tolist()}}\n",
    "            record_results(original_data, cluster_dict, results_dir, \"Hierarchical_No_Spatial\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=False)\n",
    "\n",
    "            print(f\"Cluster with spot size {(spot_size, third_dim, K)} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Hierarchical Spot Size 50 Num Clusters: 17 Total mpd 0.003053116981458475\n",
      "Method: Hierarchical Spot Size 75 Num Clusters: 17 Total mpd 0.004481702061656659\n",
      "Method: Hierarchical Spot Size 100 Num Clusters: 17 Total mpd 0.00560841868163628\n",
      "Method: Hierarchical_No_Spatial Spot Size 50 Num Clusters: 17 Total mpd 0.0029659282313437246\n",
      "Method: Hierarchical_No_Spatial Spot Size 75 Num Clusters: 17 Total mpd 0.004377434008860294\n",
      "Method: Hierarchical_No_Spatial Spot Size 100 Num Clusters: 17 Total mpd 0.005796027727486132\n"
     ]
    }
   ],
   "source": [
    "spot_sizes = [50,75,100]\n",
    "resolutions = [0.25, 0.5, 0.75, 1.0]\n",
    "methods = [\"Hierarchical\", \"Hierarchical_No_Spatial\"]\n",
    "in_billions = 1_000_000_000\n",
    "for method in methods:\n",
    "    for spot_size in spot_sizes:\n",
    "        for K in [17]:\n",
    "            filename = f\"results/hBreast/{method}/{K}/mpd/{spot_size}/{cluster_results_filename}_mpd.json\"\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename, \"r\") as mpd_dict:\n",
    "                    current_mpd = json.load(mpd_dict)\n",
    "                print(\"Method:\", method, \"Spot Size\", spot_size, \"Num Clusters:\", len(current_mpd), \"Total mpd\", sum(current_mpd.values()) / in_billions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
