{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from importlib import reload\n",
    "\n",
    "# this ensures that I can update the class without losing my variables in my notebook\n",
    "import xenium_cluster\n",
    "reload(xenium_cluster)\n",
    "from xenium_cluster import XeniumCluster\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .gz file\n",
    "file_path = 'data/hBreast/transcripts.csv.gz'\n",
    "\n",
    "# Read the gzipped CSV file into a DataFrame\n",
    "df_transcripts = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# drop cells without ids\n",
    "df_transcripts = df_transcripts[df_transcripts[\"cell_id\"] != -1]\n",
    "\n",
    "# drop blanks and controls\n",
    "df_transcripts = df_transcripts[~df_transcripts[\"feature_name\"].str.startswith('BLANK_') & ~df_transcripts[\"feature_name\"].str.startswith('NegControl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data, dataset_name: str, current_spot_size: int, third_dim: bool, resolutions: list, n_clusters=15):\n",
    "    \n",
    "    clustering = XeniumCluster(data=data, dataset_name=dataset_name)\n",
    "    clustering.set_spot_size(current_spot_size)\n",
    "    clustering.create_spot_data(third_dim=third_dim, save_data=True)\n",
    "\n",
    "    print(f\"The size of the spot data is {clustering.xenium_spot_data.shape}\")\n",
    "\n",
    "    clustering.normalize_counts(clustering.xenium_spot_data)\n",
    "    clustering.generate_neighborhood_graph(clustering.xenium_spot_data, plot_pcas=False)\n",
    "\n",
    "    BayesSpace_cluster = clustering.BayesSpace(clustering.xenium_spot_data, K=n_clusters)\n",
    "\n",
    "    return clustering, BayesSpace_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def record_results(original_data, cluster_dict, results_dir, model_name, filename, spot_size, third_dim, K=None, resolution=None, uses_spatial=True):\n",
    "\n",
    "    dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/clusters/{spot_size}\"\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    filepath = f\"{dirpath}/{filename}.json\"\n",
    "\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(cluster_dict[model_name], f, indent=4)\n",
    "\n",
    "    wss = {}\n",
    "    if resolution is not None:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim].get(\n",
    "            resolution, \n",
    "            cluster_dict[model_name][spot_size][third_dim]\n",
    "        ))\n",
    "    else:\n",
    "        current_clustering = np.array(cluster_dict[model_name][spot_size][third_dim][uses_spatial].get(\n",
    "            K, \n",
    "            cluster_dict[model_name][spot_size][third_dim][uses_spatial]\n",
    "        ))\n",
    "    cluster_labels = np.unique(current_clustering)\n",
    "\n",
    "    original_data.xenium_spot_data.obs[f\"{model_name} cluster\"] = np.array(current_clustering)\n",
    "    # Extracting row, col, and cluster values from the dataframe\n",
    "    rows = torch.tensor(original_data.xenium_spot_data.obs[\"row\"].astype(int))\n",
    "    cols = torch.tensor(original_data.xenium_spot_data.obs[\"col\"].astype(int))\n",
    "    clusters = torch.tensor(original_data.xenium_spot_data.obs[f\"{model_name} cluster\"].astype(int))\n",
    "    cluster_labels = np.unique(clusters)\n",
    "    num_clusters = len(cluster_labels)\n",
    "\n",
    "    num_rows = int(max(rows) - min(rows) + 1)\n",
    "    num_cols = int(max(cols) - min(cols) + 1)\n",
    "\n",
    "    cluster_grid = torch.zeros((num_rows, num_cols), dtype=torch.int)\n",
    "\n",
    "    cluster_grid[rows, cols] = torch.tensor(clusters, dtype=torch.int)\n",
    "\n",
    "    for label in cluster_labels:\n",
    "        current_cluster_locations = torch.stack(torch.where((cluster_grid == label)), axis=1).to(float)\n",
    "        wss[f\"Cluster {label}\"] = (spot_size ** 2) * torch.mean(torch.cdist(current_cluster_locations, current_cluster_locations)).item()\n",
    "        print(f\"POSSIBLE {len(cluster_labels)}\", label, wss[f\"Cluster {label}\"])\n",
    "\n",
    "    wss_dirpath = f\"{results_dir}/{model_name}{'/' + (str(resolution) if resolution is not None else str(K))}/wss/{spot_size}/\"\n",
    "    if not os.path.exists(wss_dirpath):\n",
    "        os.makedirs(wss_dirpath)\n",
    "\n",
    "    wss_filepath = f\"{wss_dirpath}/{filename}_wss.json\"\n",
    "    with open(wss_filepath, \"w\") as f:\n",
    "        json.dump(wss, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {\"Leiden\": {}, \"Louvain\": {}, \"Hierarchical\": {}, \"K-Means\": {}, \"BayesSpace\": {}}\n",
    "wss = {\"Leiden\": {}, \"Louvain\": {}, \"Hierarchical\": {}, \"K-Means\": {}, \"BayesSpace\": {}}\n",
    "results_dir = \"results/hBreast\"\n",
    "cluster_results_filename = \"clusters_w_plots_7_26\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the spot data is (23444, 280)\n",
      "WARNING: You’re trying to run this on 282 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: SummarizedExperiment\n",
      "Loading required package: MatrixGenerics\n",
      "Loading required package: matrixStats\n",
      "\n",
      "Attaching package: ‘MatrixGenerics’\n",
      "\n",
      "The following objects are masked from ‘package:matrixStats’:\n",
      "\n",
      "    colAlls, colAnyNAs, colAnys, colAvgsPerRowSet, colCollapse,\n",
      "    colCounts, colCummaxs, colCummins, colCumprods, colCumsums,\n",
      "    colDiffs, colIQRDiffs, colIQRs, colLogSumExps, colMadDiffs,\n",
      "    colMads, colMaxs, colMeans2, colMedians, colMins, colOrderStats,\n",
      "    colProds, colQuantiles, colRanges, colRanks, colSdDiffs, colSds,\n",
      "    colSums2, colTabulates, colVarDiffs, colVars, colWeightedMads,\n",
      "    colWeightedMeans, colWeightedMedians, colWeightedSds,\n",
      "    colWeightedVars, rowAlls, rowAnyNAs, rowAnys, rowAvgsPerColSet,\n",
      "    rowCollapse, rowCounts, rowCummaxs, rowCummins, rowCumprods,\n",
      "    rowCumsums, rowDiffs, rowIQRDiffs, rowIQRs, rowLogSumExps,\n",
      "    rowMadDiffs, rowMads, rowMaxs, rowMeans2, rowMedians, rowMins,\n",
      "    rowOrderStats, rowProds, rowQuantiles, rowRanges, rowRanks,\n",
      "    rowSdDiffs, rowSds, rowSums2, rowTabulates, rowVarDiffs, rowVars,\n",
      "    rowWeightedMads, rowWeightedMeans, rowWeightedMedians,\n",
      "    rowWeightedSds, rowWeightedVars\n",
      "\n",
      "Loading required package: GenomicRanges\n",
      "Loading required package: stats4\n",
      "Loading required package: BiocGenerics\n",
      "\n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    anyDuplicated, append, as.data.frame, basename, cbind, colnames,\n",
      "    dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep,\n",
      "    grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget,\n",
      "    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,\n",
      "    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,\n",
      "    union, unique, unsplit, which.max, which.min\n",
      "\n",
      "Loading required package: S4Vectors\n",
      "\n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    expand.grid, I, unname\n",
      "\n",
      "Loading required package: IRanges\n",
      "Loading required package: GenomeInfoDb\n",
      "Loading required package: Biobase\n",
      "Welcome to Bioconductor\n",
      "\n",
      "    Vignettes contain introductory material; view with\n",
      "    'browseVignettes()'. To cite Bioconductor, see\n",
      "    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n",
      "\n",
      "\n",
      "Attaching package: ‘Biobase’\n",
      "\n",
      "The following object is masked from ‘package:MatrixGenerics’:\n",
      "\n",
      "    rowMedians\n",
      "\n",
      "The following objects are masked from ‘package:matrixStats’:\n",
      "\n",
      "    anyMissing, rowMedians\n",
      "\n",
      "\n",
      "Attaching package: ‘Matrix’\n",
      "\n",
      "The following object is masked from ‘package:S4Vectors’:\n",
      "\n",
      "    expand\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 17"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neighbors were identified for 23441 out of 23444 spots.\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Fitting model...\n",
      "Neighbors were identified for 23441 out of 23444 spots.\n",
      "Fitting model...\n",
      "You created a large dataset with compression and chunking.\n",
      "The chunk size is equal to the dataset dimensions.\n",
      "If you want to read subsets of the dataset, you should testsmaller chunk sizes to improve read times.\n",
      "You created a large dataset with compression and chunking.\n",
      "The chunk size is equal to the dataset dimensions.\n",
      "If you want to read subsets of the dataset, you should testsmaller chunk sizes to improve read times.\n",
      "Calculating labels using iterations 100 through 1000.\n",
      "Error in file(file, ifelse(append, \"a\", \"w\")) : \n",
      "  cannot open the connection\n",
      "Calls: BayesSpace ... write.csv -> eval.parent -> eval -> eval -> <Anonymous> -> file\n",
      "In addition: Warning message:\n",
      "In file(file, ifelse(append, \"a\", \"w\")) :\n",
      "  cannot open file 'results/hBreast/BayesSpace/50/clusters_K=17.csv': No such file or directory\n",
      "Execution halted\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['Rscript', 'xenium_BayesSpace.R', 'hBreast', '50', '17']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m third_dim \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mFalse\u001b[39;00m]:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m K \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m17\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m         original_data, BayesSpace_cluster, Leiden_cluster, Louvain_cluster, hierarchical_cluster, hierarchical_cluster_no_spatial, k_means_cluster, k_means_cluster_no_spatial \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_transcripts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhBreast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspot_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthird_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolutions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# BayesSpace\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesSpace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cluster_dict:\n",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(data, dataset_name, current_spot_size, third_dim, resolutions, n_clusters)\u001b[0m\n\u001b[1;32m     16\u001b[0m Leiden_cluster \u001b[38;5;241m=\u001b[39m clustering\u001b[38;5;241m.\u001b[39mLeiden(clustering\u001b[38;5;241m.\u001b[39mxenium_spot_data, resolutions, embedding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mumap\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m Louvain_cluster \u001b[38;5;241m=\u001b[39m clustering\u001b[38;5;241m.\u001b[39mLouvain(clustering\u001b[38;5;241m.\u001b[39mxenium_spot_data, resolutions, embedding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mumap\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m BayesSpace_cluster \u001b[38;5;241m=\u001b[39m \u001b[43mclustering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBayesSpace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclustering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxenium_spot_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clustering, BayesSpace_cluster, Leiden_cluster, Louvain_cluster, hierarchical_cluster, hierarchical_cluster_no_spatial, k_means_cluster, k_means_cluster_no_spatial\n",
      "File \u001b[0;32m~/xenium/xenium_cluster.py:398\u001b[0m, in \u001b[0;36mXeniumCluster.BayesSpace\u001b[0;34m(self, data, K)\u001b[0m\n\u001b[1;32m    395\u001b[0m     command \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRscript\u001b[39m\u001b[38;5;124m\"\u001b[39m, script_path] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[1;32m    396\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(command, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 398\u001b[0m \u001b[43mrun_r_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxenium_BayesSpace.R\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSPOT_SIZE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mK\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m target_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/BayesSpace/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSPOT_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    401\u001b[0m BayesSpace_clusters \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/clusters_K=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/xenium/xenium_cluster.py:396\u001b[0m, in \u001b[0;36mXeniumCluster.BayesSpace.<locals>.run_r_script\u001b[0;34m(script_path, *args)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03mFunction to run an R script with optional arguments.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m*args: Additional arguments to pass to the R script.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    395\u001b[0m command \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRscript\u001b[39m\u001b[38;5;124m\"\u001b[39m, script_path] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m--> 396\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['Rscript', 'xenium_BayesSpace.R', 'hBreast', '50', '17']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "resolutions = [0.1, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0]\n",
    "for spot_size in [50, 75, 100]:\n",
    "    for third_dim in [False]:\n",
    "        for K in [17]:\n",
    "            original_data, BayesSpace_cluster = run_experiment(df_transcripts, \"hBreast\", spot_size, third_dim, resolutions, n_clusters=K)\n",
    "\n",
    "            # BayesSpace\n",
    "            if \"BayesSpace\" not in cluster_dict:\n",
    "                cluster_dict[\"BayesSpace\"] = {}\n",
    "            if spot_size not in cluster_dict[\"BayesSpace\"]:\n",
    "                cluster_dict[\"BayesSpace\"][spot_size] = {}\n",
    "            cluster_dict[\"BayesSpace\"][spot_size][third_dim] = {True: {K: BayesSpace_cluster.tolist()}}\n",
    "            record_results(cluster_dict, results_dir, \"BayesSpace\", cluster_results_filename, spot_size, third_dim, K, uses_spatial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE\n",
      "Method: K-Means Spot Size 100 Num Clusters: 17 Total WSS 0.005813899414138968\n",
      "HERE\n",
      "Method: K-Means_No_Spatial Spot Size 100 Num Clusters: 17 Total WSS 0.28332006679553495\n",
      "HERE\n",
      "Method: Hierarchical Spot Size 100 Num Clusters: 17 Total WSS 0.00560841868163628\n",
      "HERE\n",
      "Method: Hierarchical_No_Spatial Spot Size 100 Num Clusters: 17 Total WSS 0.28219239547169006\n",
      "Method: Leiden Spot Size 100 Resolution 0.25 Num Clusters: 6 Total WSS 0.09779246825275083\n",
      "Method: Leiden Spot Size 100 Resolution 0.5 Num Clusters: 9 Total WSS 0.12700534134305\n",
      "Method: Leiden Spot Size 100 Resolution 0.75 Num Clusters: 14 Total WSS 0.2060176697480106\n",
      "Method: Leiden Spot Size 100 Resolution 1.0 Num Clusters: 17 Total WSS 0.2464717861724789\n",
      "Method: Louvain Spot Size 100 Resolution 0.25 Num Clusters: 4 Total WSS 0.0661864015541885\n",
      "Method: Louvain Spot Size 100 Resolution 0.5 Num Clusters: 8 Total WSS 0.12385353960127954\n",
      "Method: Louvain Spot Size 100 Resolution 0.75 Num Clusters: 10 Total WSS 0.15173654314022136\n",
      "Method: Louvain Spot Size 100 Resolution 1.0 Num Clusters: 14 Total WSS 0.1888743130990558\n"
     ]
    }
   ],
   "source": [
    "spot_sizes = [50, 75, 100]\n",
    "resolutions = [0.25, 0.5, 0.75, 1.0]\n",
    "in_billions = 1_000_000_000\n",
    "method=\"BayesSpace\"\n",
    "for spot_size in spot_sizes:\n",
    "    for K in [17]:\n",
    "        filename = f\"results/hBreast/{method}/{K}/wss/{spot_size}/{cluster_results_filename}_wss.json\"\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, \"r\") as wss_dict:\n",
    "                current_wss = json.load(wss_dict)\n",
    "            print(\"Method:\", method, \"Spot Size\", spot_size, \"Num Clusters:\", len(current_wss), \"Total WSS\", sum(current_wss.values()) / in_billions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium-1YUjn3qu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
