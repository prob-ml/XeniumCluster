digraph {
	graph [size="25.65,25.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139704582300560 [label="
 (1, 180, 64, 64)" fillcolor=darkolivegreen1]
	139704582853456 [label="
 (1, 180, 64, 64)" fillcolor=darkolivegreen1]
	139704585778656 [label=ConvolutionBackward0]
	139704585778320 -> 139704585778656
	139704585778320 [label=LeakyReluBackward0]
	139704585778800 -> 139704585778320
	139704585778800 [label=NativeBatchNormBackward0]
	139704585778128 -> 139704585778800
	139704585778128 [label=ConvolutionBackward0]
	139704585780096 -> 139704585778128
	139704585780096 [label=LeakyReluBackward0]
	139704585780288 -> 139704585780096
	139704585780288 [label=NativeBatchNormBackward0]
	139704585780384 -> 139704585780288
	139704585780384 [label=ConvolutionBackward0]
	139704585780576 -> 139704585780384
	139704585780576 [label=NativeBatchNormBackward0]
	139704585780768 -> 139704585780576
	139704585780768 [label=ConvolutionBackward0]
	139704585780960 -> 139704585780768
	139704585780960 [label=LeakyReluBackward0]
	139704585781152 -> 139704585780960
	139704585781152 [label=NativeBatchNormBackward0]
	139704585781200 -> 139704585781152
	139704585781200 [label=ConvolutionBackward0]
	139704582930688 -> 139704585781200
	139704582930688 [label=LeakyReluBackward0]
	139704582930880 -> 139704582930688
	139704582930880 [label=NativeBatchNormBackward0]
	139704582930976 -> 139704582930880
	139704582930976 [label=ConvolutionBackward0]
	139704582931168 -> 139704582930976
	139704582848576 [label="enc_conv1.weight
 (90, 180, 5, 5)" fillcolor=lightblue]
	139704582848576 -> 139704582931168
	139704582931168 [label=AccumulateGrad]
	139704582931120 -> 139704582930976
	139704582848656 [label="enc_conv1.bias
 (90)" fillcolor=lightblue]
	139704582848656 -> 139704582931120
	139704582931120 [label=AccumulateGrad]
	139704582930928 -> 139704582930880
	139704582848736 [label="enc_batchnorm1.weight
 (90)" fillcolor=lightblue]
	139704582848736 -> 139704582930928
	139704582930928 [label=AccumulateGrad]
	139704582930784 -> 139704582930880
	139704582848816 [label="enc_batchnorm1.bias
 (90)" fillcolor=lightblue]
	139704582848816 -> 139704582930784
	139704582930784 [label=AccumulateGrad]
	139704582930640 -> 139704585781200
	139704582849296 [label="enc_conv2.weight
 (45, 90, 5, 5)" fillcolor=lightblue]
	139704582849296 -> 139704582930640
	139704582930640 [label=AccumulateGrad]
	139704582930592 -> 139704585781200
	139704582849376 [label="enc_conv2.bias
 (45)" fillcolor=lightblue]
	139704582849376 -> 139704582930592
	139704582930592 [label=AccumulateGrad]
	139704585781056 -> 139704585781152
	139704582849456 [label="enc_batchnorm2.weight
 (45)" fillcolor=lightblue]
	139704582849456 -> 139704585781056
	139704585781056 [label=AccumulateGrad]
	139704582930496 -> 139704585781152
	139704582849536 [label="enc_batchnorm2.bias
 (45)" fillcolor=lightblue]
	139704582849536 -> 139704582930496
	139704582930496 [label=AccumulateGrad]
	139704585780912 -> 139704585780768
	139704582850016 [label="enc_conv3.weight
 (15, 45, 5, 5)" fillcolor=lightblue]
	139704582850016 -> 139704585780912
	139704585780912 [label=AccumulateGrad]
	139704585780864 -> 139704585780768
	139704582850096 [label="enc_conv3.bias
 (15)" fillcolor=lightblue]
	139704582850096 -> 139704585780864
	139704585780864 [label=AccumulateGrad]
	139704585780720 -> 139704585780576
	139704582850176 [label="enc_batchnorm3.weight
 (15)" fillcolor=lightblue]
	139704582850176 -> 139704585780720
	139704585780720 [label=AccumulateGrad]
	139704585780672 -> 139704585780576
	139704582850256 [label="enc_batchnorm3.bias
 (15)" fillcolor=lightblue]
	139704582850256 -> 139704585780672
	139704585780672 [label=AccumulateGrad]
	139704585780528 -> 139704585780384
	139704582850736 [label="dec_conv1.weight
 (45, 15, 5, 5)" fillcolor=lightblue]
	139704582850736 -> 139704585780528
	139704585780528 [label=AccumulateGrad]
	139704585780480 -> 139704585780384
	139704582850816 [label="dec_conv1.bias
 (45)" fillcolor=lightblue]
	139704582850816 -> 139704585780480
	139704585780480 [label=AccumulateGrad]
	139704585780336 -> 139704585780288
	139704582850896 [label="dec_batchnorm1.weight
 (45)" fillcolor=lightblue]
	139704582850896 -> 139704585780336
	139704585780336 [label=AccumulateGrad]
	139704585780192 -> 139704585780288
	139704582850976 [label="dec_batchnorm1.bias
 (45)" fillcolor=lightblue]
	139704582850976 -> 139704585780192
	139704585780192 [label=AccumulateGrad]
	139704585780048 -> 139704585778128
	139704582851456 [label="dec_conv2.weight
 (90, 45, 5, 5)" fillcolor=lightblue]
	139704582851456 -> 139704585780048
	139704585780048 [label=AccumulateGrad]
	139704585777984 -> 139704585778128
	139704582851536 [label="dec_conv2.bias
 (90)" fillcolor=lightblue]
	139704582851536 -> 139704585777984
	139704585777984 [label=AccumulateGrad]
	139704585778176 -> 139704585778800
	139704582851616 [label="dec_batchnorm2.weight
 (90)" fillcolor=lightblue]
	139704582851616 -> 139704585778176
	139704585778176 [label=AccumulateGrad]
	139704585778560 -> 139704585778800
	139704582851696 [label="dec_batchnorm2.bias
 (90)" fillcolor=lightblue]
	139704582851696 -> 139704585778560
	139704585778560 [label=AccumulateGrad]
	139704585778416 -> 139704585778656
	139704582852096 [label="dec_conv3.weight
 (180, 90, 5, 5)" fillcolor=lightblue]
	139704582852096 -> 139704585778416
	139704585778416 [label=AccumulateGrad]
	139704585778368 -> 139704585778656
	139704582852176 [label="dec_conv3.bias
 (180)" fillcolor=lightblue]
	139704582852176 -> 139704585778368
	139704585778368 [label=AccumulateGrad]
	139704585778656 -> 139704582853456
	139704582614816 [label="
 (4096, 15)" fillcolor=darkolivegreen1]
	139704585778272 [label=ViewBackward0]
	139704585780576 -> 139704585778272
	139704585778272 -> 139704582614816
	139704582852896 [label="
 (1, 15, 64, 64)" fillcolor=darkolivegreen3]
	139704585780576 -> 139704582852896
	139704582852896 -> 139704582614816 [style=dotted]
	139704582854016 [label="
 (4096, 10)" fillcolor=darkolivegreen1]
	139704585780144 [label=SoftmaxBackward0]
	139704585780240 -> 139704585780144
	139704585780240 [label=AddmmBackward0]
	139704585780624 -> 139704585780240
	139704582852576 [label="clust_linear3.bias
 (10)" fillcolor=lightblue]
	139704582852576 -> 139704585780624
	139704585780624 [label=AccumulateGrad]
	139704585780432 -> 139704585780240
	139704585780432 [label=LeakyReluBackward0]
	139704585781008 -> 139704585780432
	139704585781008 [label=AddmmBackward0]
	139704582930832 -> 139704585781008
	139704582852416 [label="clust_linear2.bias
 (16)" fillcolor=lightblue]
	139704582852416 -> 139704582930832
	139704582930832 [label=AccumulateGrad]
	139704582930736 -> 139704585781008
	139704582930736 [label=LeakyReluBackward0]
	139704582931072 -> 139704582930736
	139704582931072 [label=AddmmBackward0]
	139704582931360 -> 139704582931072
	139704582852256 [label="clust_linear1.bias
 (32)" fillcolor=lightblue]
	139704582852256 -> 139704582931360
	139704582931360 [label=AccumulateGrad]
	139704585778272 -> 139704582931072
	139704582931312 -> 139704582931072
	139704582931312 [label=TBackward0]
	139704582931408 -> 139704582931312
	139704582852016 [label="clust_linear1.weight
 (32, 15)" fillcolor=lightblue]
	139704582852016 -> 139704582931408
	139704582931408 [label=AccumulateGrad]
	139704582930544 -> 139704585781008
	139704582930544 [label=TBackward0]
	139704582931456 -> 139704582930544
	139704582852336 [label="clust_linear2.weight
 (16, 32)" fillcolor=lightblue]
	139704582852336 -> 139704582931456
	139704582931456 [label=AccumulateGrad]
	139704585778032 -> 139704585780240
	139704585778032 [label=TBackward0]
	139704585781104 -> 139704585778032
	139704582852496 [label="clust_linear3.weight
 (10, 16)" fillcolor=lightblue]
	139704582852496 -> 139704585781104
	139704585781104 [label=AccumulateGrad]
	139704585780144 -> 139704582854016
}
